{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aaa7f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adbhut/Desktop/study_material/pii_removal/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"<huggingface token>\"\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f52e8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openai-community/gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdea7695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "# Add special tokens\n",
    "special_tokens = {\"additional_special_tokens\": [\"<input>\", \"</input>\", \"<pii_removed>\", \"</pii_removed>\"]}\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "# Set </pii_removed> as the EOS token\n",
    "tokenizer.eos_token = \"</pii_removed>\"\n",
    "tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids(\"</pii_removed>\")\n",
    "\n",
    "# Make sure the pad_token is also set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Define the chat template using Jinja2 format\n",
    "chat_template = \"\"\"{% for msg in messages %}\n",
    "<{{ msg.role }}>{{ msg.content }}</{{ msg.role }}>\n",
    "{% endfor %}\n",
    "{% if add_generation_prompt %}\n",
    "<pii_removed>{% endif %}\"\"\"\n",
    "\n",
    "# Set the chat template\n",
    "tokenizer.chat_template = chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a576d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\"role\": \"input\", \"content\": \"My name is Adbhut\"},\n",
    "        {\"role\": \"pii_removed\", \"content\": \"My name is [[PII]]\"},\n",
    "    ],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=False,\n",
    "    continue_final_message=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d504ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<input>My name is Adbhut</input>\n",
      "<pii_removed>My name is [[PII]]</pii_removed>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f36947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9414d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"input\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "max_new_tokens = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3895605e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<input>Who are you?</input>\n",
      "<pii_removed>\n"
     ]
    }
   ],
   "source": [
    "prompt_text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True,\n",
    ")\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3353b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50257,  8241,   389,   345,    30, 50258,   198, 50259]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(prompt_text, return_tensors=\"pt\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f794a498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pii_removed>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(50259)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11bd9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "393ed410",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(\n",
    "    **tokens, max_new_tokens=max_new_tokens, pad_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6f32a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = tokenizer.decode(output[0], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56073951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<input>Who are you?</input>\n",
      "<pii_removed>Who are you?\n",
      "                                                                                                                                                                                 \n"
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c381d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593d8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
