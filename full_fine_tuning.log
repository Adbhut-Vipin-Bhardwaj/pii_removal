Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Generating train split:   0%|          | 0/464150 [00:00<?, ? examples/s]Generating train split:  11%|█         | 50996/464150 [00:00<00:00, 434788.15 examples/s]Generating train split:  22%|██▏       | 102453/464150 [00:00<00:00, 452132.90 examples/s]Generating train split:  33%|███▎      | 154611/464150 [00:00<00:00, 472526.59 examples/s]Generating train split:  44%|████▍     | 206150/464150 [00:00<00:00, 471567.06 examples/s]Generating train split:  57%|█████▋    | 266254/464150 [00:00<00:00, 498368.47 examples/s]Generating train split:  70%|███████   | 326210/464150 [00:00<00:00, 510061.28 examples/s]Generating train split:  83%|████████▎ | 386283/464150 [00:00<00:00, 499020.01 examples/s]Generating train split:  96%|█████████▋| 446825/464150 [00:00<00:00, 516150.42 examples/s]Generating train split: 100%|██████████| 464150/464150 [00:00<00:00, 500413.12 examples/s]
Generating validation split:   0%|          | 0/116077 [00:00<?, ? examples/s]Generating validation split:  59%|█████▉    | 68491/116077 [00:00<00:00, 529535.73 examples/s]Generating validation split: 100%|██████████| 116077/116077 [00:00<00:00, 526504.88 examples/s]
Filter:   0%|          | 0/464150 [00:00<?, ? examples/s]Filter:   0%|          | 2000/464150 [00:00<00:25, 18180.14 examples/s]Filter:   1%|          | 4000/464150 [00:00<00:24, 18930.20 examples/s]Filter:   2%|▏         | 8000/464150 [00:00<00:21, 21020.97 examples/s]Filter:   2%|▏         | 11000/464150 [00:00<00:22, 19897.31 examples/s]Filter:   3%|▎         | 13000/464150 [00:00<00:23, 19488.91 examples/s]Filter:   3%|▎         | 15000/464150 [00:00<00:23, 19447.39 examples/s]Filter:   4%|▍         | 19000/464150 [00:00<00:21, 20533.59 examples/s]Filter:   5%|▍         | 22000/464150 [00:01<00:21, 20204.21 examples/s]Filter:   6%|▌         | 26000/464150 [00:01<00:21, 20503.85 examples/s]Filter:   6%|▋         | 30000/464150 [00:01<00:20, 21145.39 examples/s]Filter:   7%|▋         | 33000/464150 [00:01<00:21, 20516.88 examples/s]Filter:   8%|▊         | 36000/464150 [00:01<00:20, 20521.70 examples/s]Filter:   8%|▊         | 39000/464150 [00:01<00:20, 20964.69 examples/s]Filter:   9%|▉         | 42000/464150 [00:02<00:20, 20164.22 examples/s]Filter:  10%|▉         | 46000/464150 [00:02<00:20, 20133.64 examples/s]Filter:  11%|█         | 50000/464150 [00:02<00:20, 20535.93 examples/s]Filter:  11%|█▏        | 53000/464150 [00:02<00:20, 20089.39 examples/s]Filter:  12%|█▏        | 57000/464150 [00:02<00:20, 20211.35 examples/s]Filter:  13%|█▎        | 61000/464150 [00:02<00:19, 21133.63 examples/s]Filter:  14%|█▍        | 65000/464150 [00:03<00:19, 20748.68 examples/s]Filter:  15%|█▍        | 69000/464150 [00:03<00:18, 20853.65 examples/s]Filter:  16%|█▌        | 72000/464150 [00:03<00:22, 17439.75 examples/s]Filter:  16%|█▌        | 74000/464150 [00:03<00:22, 17696.25 examples/s]Filter:  17%|█▋        | 77000/464150 [00:03<00:21, 18117.93 examples/s]Filter:  17%|█▋        | 81000/464150 [00:04<00:19, 19772.31 examples/s]Filter:  18%|█▊        | 84000/464150 [00:04<00:19, 19491.08 examples/s]Filter:  19%|█▉        | 88000/464150 [00:04<00:18, 20449.51 examples/s]Filter:  20%|█▉        | 91000/464150 [00:04<00:18, 20074.43 examples/s]Filter:  20%|██        | 94000/464150 [00:04<00:18, 20140.14 examples/s]Filter:  21%|██        | 98000/464150 [00:04<00:17, 20547.21 examples/s]Filter:  22%|██▏       | 101000/464150 [00:05<00:18, 19814.16 examples/s]Filter:  22%|██▏       | 103000/464150 [00:05<00:18, 19619.51 examples/s]Filter:  23%|██▎       | 107000/464150 [00:05<00:17, 20297.74 examples/s]Filter:  24%|██▍       | 111000/464150 [00:05<00:17, 20294.35 examples/s]Filter:  25%|██▍       | 115000/464150 [00:05<00:16, 20757.97 examples/s]Filter:  25%|██▌       | 118000/464150 [00:05<00:17, 20208.31 examples/s]Filter:  26%|██▌       | 121000/464150 [00:06<00:17, 19955.91 examples/s]Filter:  27%|██▋       | 125000/464150 [00:06<00:16, 20540.78 examples/s]Filter:  28%|██▊       | 129000/464150 [00:06<00:15, 21081.32 examples/s]Filter:  29%|██▊       | 133000/464150 [00:06<00:15, 20812.76 examples/s]Filter:  30%|██▉       | 137000/464150 [00:06<00:15, 21499.49 examples/s]Filter:  30%|███       | 140000/464150 [00:06<00:15, 21072.54 examples/s]Filter:  31%|███       | 144000/464150 [00:07<00:15, 20753.77 examples/s]Filter:  32%|███▏      | 148000/464150 [00:07<00:15, 21045.70 examples/s]Filter:  33%|███▎      | 152000/464150 [00:07<00:15, 20663.38 examples/s]Filter:  34%|███▎      | 156000/464150 [00:07<00:14, 21015.25 examples/s]Filter:  34%|███▍      | 159000/464150 [00:07<00:14, 20457.84 examples/s]Filter:  35%|███▌      | 163000/464150 [00:08<00:14, 20483.82 examples/s]Filter:  36%|███▌      | 166000/464150 [00:08<00:14, 20907.63 examples/s]Filter:  36%|███▋      | 169000/464150 [00:08<00:14, 20438.03 examples/s]Filter:  37%|███▋      | 172000/464150 [00:08<00:14, 20586.78 examples/s]Filter:  38%|███▊      | 175000/464150 [00:08<00:13, 20924.63 examples/s]Filter:  39%|███▊      | 179000/464150 [00:08<00:13, 20680.86 examples/s]Filter:  39%|███▉      | 183000/464150 [00:08<00:13, 21295.23 examples/s]Filter:  40%|████      | 186000/464150 [00:09<00:13, 21003.96 examples/s]Filter:  41%|████      | 189000/464150 [00:09<00:13, 20442.03 examples/s]Filter:  41%|████▏     | 192000/464150 [00:09<00:13, 20329.99 examples/s]Filter:  42%|████▏     | 196000/464150 [00:09<00:14, 18938.26 examples/s]Filter:  43%|████▎     | 199000/464150 [00:09<00:13, 19724.36 examples/s]Filter:  44%|████▎     | 202000/464150 [00:09<00:13, 19862.37 examples/s]Filter:  44%|████▍     | 206000/464150 [00:10<00:12, 20489.09 examples/s]Filter:  45%|████▌     | 209000/464150 [00:10<00:12, 20100.03 examples/s]Filter:  46%|████▌     | 213000/464150 [00:10<00:12, 20925.89 examples/s]Filter:  47%|████▋     | 216000/464150 [00:10<00:12, 20304.22 examples/s]Filter:  47%|████▋     | 219000/464150 [00:10<00:12, 20060.12 examples/s]Filter:  48%|████▊     | 223000/464150 [00:10<00:11, 20815.20 examples/s]Filter:  49%|████▊     | 226000/464150 [00:11<00:11, 20280.47 examples/s]Filter:  50%|████▉     | 230000/464150 [00:11<00:11, 21021.92 examples/s]Filter:  50%|█████     | 233000/464150 [00:11<00:11, 20555.90 examples/s]Filter:  51%|█████     | 236000/464150 [00:11<00:11, 20144.08 examples/s]Filter:  52%|█████▏    | 240000/464150 [00:11<00:10, 20386.65 examples/s]Filter:  53%|█████▎    | 244000/464150 [00:11<00:10, 21323.55 examples/s]Filter:  53%|█████▎    | 247000/464150 [00:12<00:10, 20780.60 examples/s]Filter:  54%|█████▍    | 251000/464150 [00:12<00:10, 20941.48 examples/s]Filter:  55%|█████▍    | 255000/464150 [00:12<00:09, 21577.18 examples/s]Filter:  56%|█████▌    | 258000/464150 [00:12<00:09, 20822.26 examples/s]Filter:  56%|█████▌    | 261000/464150 [00:12<00:09, 20752.16 examples/s]Filter:  57%|█████▋    | 265000/464150 [00:12<00:09, 21096.41 examples/s]Filter:  58%|█████▊    | 269000/464150 [00:13<00:09, 20757.49 examples/s]Filter:  59%|█████▉    | 273000/464150 [00:13<00:09, 21040.50 examples/s]Filter:  59%|█████▉    | 276000/464150 [00:13<00:09, 20351.78 examples/s]Filter:  60%|██████    | 280000/464150 [00:13<00:09, 20429.71 examples/s]Filter:  61%|██████    | 283000/464150 [00:13<00:08, 20752.17 examples/s]Filter:  62%|██████▏   | 287000/464150 [00:14<00:08, 20690.05 examples/s]Filter:  62%|██████▏   | 290000/464150 [00:14<00:08, 21081.30 examples/s]Filter:  63%|██████▎   | 293000/464150 [00:14<00:08, 20399.60 examples/s]Filter:  64%|██████▍   | 296000/464150 [00:14<00:08, 20101.79 examples/s]Filter:  65%|██████▍   | 300000/464150 [00:14<00:07, 20540.04 examples/s]Filter:  65%|██████▌   | 304000/464150 [00:14<00:07, 21180.55 examples/s]Filter:  66%|██████▋   | 308000/464150 [00:15<00:07, 20706.22 examples/s]Filter:  67%|██████▋   | 312000/464150 [00:15<00:07, 21272.73 examples/s]Filter:  68%|██████▊   | 315000/464150 [00:15<00:07, 21238.22 examples/s]Filter:  69%|██████▊   | 318000/464150 [00:15<00:07, 20740.87 examples/s]Filter:  69%|██████▉   | 322000/464150 [00:15<00:06, 21163.95 examples/s]Filter:  70%|███████   | 325000/464150 [00:15<00:07, 18600.20 examples/s]Filter:  70%|███████   | 327000/464150 [00:16<00:07, 18752.87 examples/s]Filter:  71%|███████   | 330000/464150 [00:16<00:06, 19215.30 examples/s]Filter:  72%|███████▏  | 334000/464150 [00:16<00:06, 20084.84 examples/s]Filter:  73%|███████▎  | 338000/464150 [00:16<00:06, 20314.81 examples/s]Filter:  73%|███████▎  | 341000/464150 [00:16<00:05, 20642.17 examples/s]Filter:  74%|███████▍  | 344000/464150 [00:16<00:05, 20288.08 examples/s]Filter:  75%|███████▍  | 348000/464150 [00:17<00:05, 20854.62 examples/s]Filter:  76%|███████▌  | 351000/464150 [00:17<00:05, 20617.58 examples/s]Filter:  76%|███████▋  | 354000/464150 [00:17<00:05, 20034.53 examples/s]Filter:  77%|███████▋  | 358000/464150 [00:17<00:05, 20049.24 examples/s]Filter:  78%|███████▊  | 362000/464150 [00:17<00:04, 20907.36 examples/s]Filter:  79%|███████▊  | 365000/464150 [00:17<00:04, 20908.08 examples/s]Filter:  79%|███████▉  | 368000/464150 [00:18<00:04, 20675.20 examples/s]Filter:  80%|████████  | 372000/464150 [00:18<00:04, 21340.35 examples/s]Filter:  81%|████████  | 375000/464150 [00:18<00:04, 21160.47 examples/s]Filter:  82%|████████▏ | 379000/464150 [00:18<00:04, 20712.92 examples/s]Filter:  83%|████████▎ | 383000/464150 [00:18<00:03, 21068.22 examples/s]Filter:  83%|████████▎ | 386000/464150 [00:18<00:03, 20517.64 examples/s]Filter:  84%|████████▍ | 390000/464150 [00:19<00:03, 21078.97 examples/s]Filter:  85%|████████▍ | 393000/464150 [00:19<00:03, 20501.28 examples/s]Filter:  85%|████████▌ | 396000/464150 [00:19<00:03, 20201.99 examples/s]Filter:  86%|████████▌ | 400000/464150 [00:19<00:03, 20997.95 examples/s]Filter:  87%|████████▋ | 404000/464150 [00:19<00:02, 20597.02 examples/s]Filter:  88%|████████▊ | 408000/464150 [00:19<00:02, 21075.53 examples/s]Filter:  89%|████████▊ | 411000/464150 [00:20<00:02, 20415.13 examples/s]Filter:  89%|████████▉ | 414000/464150 [00:20<00:02, 20136.56 examples/s]Filter:  90%|█████████ | 418000/464150 [00:20<00:02, 20536.25 examples/s]Filter:  91%|█████████ | 422000/464150 [00:20<00:01, 21255.50 examples/s]Filter:  92%|█████████▏| 426000/464150 [00:20<00:01, 20880.62 examples/s]Filter:  92%|█████████▏| 429000/464150 [00:20<00:01, 20193.35 examples/s]Filter:  93%|█████████▎| 432000/464150 [00:21<00:01, 20269.69 examples/s]Filter:  94%|█████████▎| 435000/464150 [00:21<00:01, 19620.05 examples/s]Filter:  94%|█████████▍| 437000/464150 [00:21<00:01, 19534.61 examples/s]Filter:  95%|█████████▌| 441000/464150 [00:21<00:01, 19776.40 examples/s]Filter:  95%|█████████▌| 443000/464150 [00:21<00:01, 19150.97 examples/s]Filter:  96%|█████████▌| 445000/464150 [00:21<00:01, 19077.83 examples/s]Filter:  97%|█████████▋| 449000/464150 [00:22<00:00, 19727.28 examples/s]Filter:  97%|█████████▋| 451000/464150 [00:22<00:00, 19323.04 examples/s]Filter:  98%|█████████▊| 453000/464150 [00:22<00:00, 19267.05 examples/s]Filter:  98%|█████████▊| 456000/464150 [00:22<00:00, 19882.88 examples/s]Filter:  99%|█████████▉| 460000/464150 [00:22<00:00, 20529.19 examples/s]Filter: 100%|█████████▉| 464000/464150 [00:22<00:00, 16688.38 examples/s]Filter: 100%|██████████| 464150/464150 [00:22<00:00, 20287.98 examples/s]
Filter:   0%|          | 0/116077 [00:00<?, ? examples/s]Filter:   3%|▎         | 3000/116077 [00:00<00:05, 19084.45 examples/s]Filter:   5%|▌         | 6000/116077 [00:00<00:05, 19675.67 examples/s]Filter:   8%|▊         | 9000/116077 [00:00<00:05, 20078.45 examples/s]Filter:  11%|█         | 13000/116077 [00:00<00:05, 19938.93 examples/s]Filter:  14%|█▍        | 16000/116077 [00:00<00:04, 20128.49 examples/s]Filter:  16%|█▋        | 19000/116077 [00:00<00:04, 19948.20 examples/s]Filter:  20%|█▉        | 23000/116077 [00:01<00:04, 20213.79 examples/s]Filter:  22%|██▏       | 26000/116077 [00:01<00:04, 20034.13 examples/s]Filter:  25%|██▍       | 29000/116077 [00:01<00:04, 20059.39 examples/s]Filter:  28%|██▊       | 32000/116077 [00:01<00:04, 20051.88 examples/s]Filter:  30%|███       | 35000/116077 [00:01<00:04, 20111.40 examples/s]Filter:  33%|███▎      | 38000/116077 [00:01<00:03, 19959.30 examples/s]Filter:  34%|███▍      | 40000/116077 [00:02<00:03, 19901.62 examples/s]Filter:  38%|███▊      | 44000/116077 [00:02<00:03, 20027.02 examples/s]Filter:  40%|████      | 47000/116077 [00:02<00:03, 20090.89 examples/s]Filter:  43%|████▎     | 50000/116077 [00:02<00:03, 20069.29 examples/s]Filter:  47%|████▋     | 54000/116077 [00:02<00:03, 20165.44 examples/s]Filter:  50%|████▉     | 58000/116077 [00:02<00:02, 20421.83 examples/s]Filter:  53%|█████▎    | 61000/116077 [00:03<00:02, 20487.12 examples/s]Filter:  55%|█████▌    | 64000/116077 [00:03<00:02, 20594.15 examples/s]Filter:  58%|█████▊    | 67000/116077 [00:03<00:02, 20395.09 examples/s]Filter:  61%|██████    | 71000/116077 [00:03<00:02, 20417.55 examples/s]Filter:  64%|██████▍   | 74000/116077 [00:03<00:02, 20396.25 examples/s]Filter:  67%|██████▋   | 78000/116077 [00:03<00:01, 20781.55 examples/s]Filter:  70%|██████▉   | 81000/116077 [00:04<00:01, 20597.20 examples/s]Filter:  72%|███████▏  | 84000/116077 [00:04<00:01, 20553.48 examples/s]Filter:  76%|███████▌  | 88000/116077 [00:04<00:01, 20518.91 examples/s]Filter:  78%|███████▊  | 91000/116077 [00:04<00:01, 20627.99 examples/s]Filter:  81%|████████  | 94000/116077 [00:04<00:01, 20601.64 examples/s]Filter:  84%|████████▍ | 98000/116077 [00:04<00:00, 20565.26 examples/s]Filter:  87%|████████▋ | 101000/116077 [00:04<00:00, 20564.36 examples/s]Filter:  90%|█████████ | 105000/116077 [00:05<00:00, 20662.93 examples/s]Filter:  93%|█████████▎| 108000/116077 [00:05<00:00, 20709.17 examples/s]Filter:  96%|█████████▌| 111000/116077 [00:05<00:00, 20585.27 examples/s]Filter:  99%|█████████▉| 115000/116077 [00:05<00:00, 18675.22 examples/s]Filter: 100%|██████████| 116077/116077 [00:05<00:00, 20152.79 examples/s]
Map:   0%|          | 0/90533 [00:00<?, ? examples/s]Map:   2%|▏         | 1503/90533 [00:00<00:05, 14952.05 examples/s]Map:   3%|▎         | 3004/90533 [00:00<00:05, 14980.54 examples/s]Map:   5%|▌         | 4534/90533 [00:00<00:05, 15118.79 examples/s]Map:   8%|▊         | 6809/90533 [00:00<00:05, 15135.91 examples/s]Map:  10%|█         | 9056/90533 [00:00<00:05, 15066.09 examples/s]Map:  12%|█▏        | 10579/90533 [00:00<00:05, 15109.44 examples/s]Map:  14%|█▍        | 12851/90533 [00:00<00:05, 15118.55 examples/s]Map:  17%|█▋        | 15109/90533 [00:01<00:04, 15090.43 examples/s]Map:  18%|█▊        | 16633/90533 [00:01<00:04, 15124.90 examples/s]Map:  21%|██        | 18901/90533 [00:01<00:04, 15120.89 examples/s]Map:  23%|██▎       | 21142/90533 [00:01<00:04, 15056.71 examples/s]Map:  25%|██▌       | 22674/90533 [00:01<00:04, 15116.71 examples/s]Map:  28%|██▊       | 24952/90533 [00:01<00:04, 15136.81 examples/s]Map:  30%|███       | 27194/90533 [00:01<00:04, 15068.96 examples/s]Map:  32%|███▏      | 28718/90533 [00:01<00:04, 15108.36 examples/s]Map:  34%|███▍      | 30997/90533 [00:02<00:03, 15134.23 examples/s]Map:  37%|███▋      | 33235/90533 [00:02<00:03, 15059.87 examples/s]Map:  38%|███▊      | 34778/90533 [00:02<00:03, 15098.24 examples/s]Map:  41%|████      | 37005/90533 [00:02<00:03, 15013.01 examples/s]Map:  43%|████▎     | 38536/90533 [00:02<00:03, 15081.99 examples/s]Map:  45%|████▌     | 40812/90533 [00:02<00:03, 15110.10 examples/s]Map:  48%|████▊     | 43053/90533 [00:02<00:03, 15051.35 examples/s]Map:  49%|████▉     | 44575/90533 [00:02<00:03, 15090.34 examples/s]Map:  52%|█████▏    | 46829/90533 [00:03<00:02, 15063.90 examples/s]Map:  54%|█████▍    | 48851/90533 [00:03<00:02, 14544.96 examples/s]Map:  56%|█████▌    | 50344/90533 [00:03<00:02, 14632.28 examples/s]Map:  57%|█████▋    | 51858/90533 [00:03<00:02, 14757.98 examples/s]Map:  59%|█████▉    | 53357/90533 [00:03<00:02, 14816.84 examples/s]Map:  61%|██████    | 54879/90533 [00:03<00:02, 14925.12 examples/s]Map:  63%|██████▎   | 57095/90533 [00:03<00:02, 14865.66 examples/s]Map:  65%|██████▍   | 58588/90533 [00:03<00:02, 14880.08 examples/s]Map:  67%|██████▋   | 60815/90533 [00:04<00:01, 14863.93 examples/s]Map:  70%|██████▉   | 63011/90533 [00:04<00:01, 14784.95 examples/s]Map:  72%|███████▏  | 65040/90533 [00:04<00:01, 14371.60 examples/s]Map:  74%|███████▎  | 66563/90533 [00:04<00:01, 14571.35 examples/s]Map:  75%|███████▌  | 68059/90533 [00:04<00:01, 14667.89 examples/s]Map:  77%|███████▋  | 69597/90533 [00:04<00:01, 14854.99 examples/s]Map:  79%|███████▊  | 71098/90533 [00:04<00:01, 14895.89 examples/s]Map:  80%|████████  | 72634/90533 [00:04<00:01, 15023.11 examples/s]Map:  82%|████████▏ | 74144/90533 [00:04<00:01, 15040.81 examples/s]Map:  84%|████████▎ | 75689/90533 [00:05<00:00, 15155.02 examples/s]Map:  86%|████████▌ | 77958/90533 [00:05<00:00, 15138.86 examples/s]Map:  89%|████████▊ | 80204/90533 [00:05<00:00, 15075.54 examples/s]Map:  90%|█████████ | 81731/90533 [00:05<00:00, 15122.47 examples/s]Map:  93%|█████████▎| 83934/90533 [00:05<00:00, 14967.03 examples/s]Map:  95%|█████████▌| 86051/90533 [00:05<00:00, 14680.12 examples/s]Map:  97%|█████████▋| 87543/90533 [00:05<00:00, 14735.40 examples/s]Map:  98%|█████████▊| 89033/90533 [00:05<00:00, 14775.78 examples/s]Map: 100%|██████████| 90533/90533 [00:06<00:00, 14948.93 examples/s]
Map:   0%|          | 0/30000 [00:00<?, ? examples/s]Map:   5%|▌         | 1529/30000 [00:00<00:01, 15196.03 examples/s]Map:  10%|█         | 3057/30000 [00:00<00:01, 15240.04 examples/s]Map:  15%|█▌        | 4609/30000 [00:00<00:01, 15363.93 examples/s]Map:  23%|██▎       | 6926/30000 [00:00<00:01, 15399.11 examples/s]Map:  31%|███       | 9215/30000 [00:00<00:01, 15337.48 examples/s]Map:  36%|███▌      | 10791/30000 [00:00<00:01, 15396.86 examples/s]Map:  44%|████▎     | 13081/30000 [00:00<00:01, 15342.27 examples/s]Map:  49%|████▉     | 14633/30000 [00:00<00:00, 15384.97 examples/s]Map:  56%|█████▋    | 16940/30000 [00:01<00:00, 15380.24 examples/s]Map:  64%|██████▍   | 19232/30000 [00:01<00:00, 15342.32 examples/s]Map:  69%|██████▉   | 20789/30000 [00:01<00:00, 15387.89 examples/s]Map:  77%|███████▋  | 23086/30000 [00:01<00:00, 15357.36 examples/s]Map:  82%|████████▏ | 24641/30000 [00:01<00:00, 15404.37 examples/s]Map:  90%|████████▉ | 26961/30000 [00:01<00:00, 15422.86 examples/s]Map:  98%|█████████▊| 29253/30000 [00:01<00:00, 15372.82 examples/s]Map: 100%|██████████| 30000/30000 [00:01<00:00, 15358.75 examples/s]
Converting train dataset to ChatML:   0%|          | 0/90533 [00:00<?, ? examples/s]Converting train dataset to ChatML:   4%|▎         | 3303/90533 [00:00<00:02, 32912.01 examples/s]Converting train dataset to ChatML:   7%|▋         | 6707/90533 [00:00<00:02, 33288.67 examples/s]Converting train dataset to ChatML:  13%|█▎        | 11373/90533 [00:00<00:02, 26933.32 examples/s]Converting train dataset to ChatML:  16%|█▋        | 14755/90533 [00:00<00:02, 29048.51 examples/s]Converting train dataset to ChatML:  20%|█▉        | 18082/90533 [00:00<00:02, 30335.30 examples/s]Converting train dataset to ChatML:  24%|██▎       | 21472/90533 [00:00<00:02, 31415.30 examples/s]Converting train dataset to ChatML:  27%|██▋       | 24861/90533 [00:00<00:02, 32159.83 examples/s]Converting train dataset to ChatML:  31%|███       | 28197/90533 [00:00<00:01, 32517.47 examples/s]Converting train dataset to ChatML:  35%|███▍      | 31577/90533 [00:01<00:01, 32903.33 examples/s]Converting train dataset to ChatML:  39%|███▊      | 34962/90533 [00:01<00:01, 33185.92 examples/s]Converting train dataset to ChatML:  44%|████▍     | 40000/90533 [00:01<00:01, 33227.56 examples/s]Converting train dataset to ChatML:  48%|████▊     | 43382/90533 [00:01<00:01, 33386.23 examples/s]Converting train dataset to ChatML:  52%|█████▏    | 46778/90533 [00:01<00:01, 33544.32 examples/s]Converting train dataset to ChatML:  57%|█████▋    | 51839/90533 [00:01<00:01, 33613.87 examples/s]Converting train dataset to ChatML:  63%|██████▎   | 56889/90533 [00:01<00:01, 33628.98 examples/s]Converting train dataset to ChatML:  68%|██████▊   | 61949/90533 [00:01<00:00, 33659.67 examples/s]Converting train dataset to ChatML:  74%|███████▍  | 66995/90533 [00:02<00:00, 33651.47 examples/s]Converting train dataset to ChatML:  80%|███████▉  | 71986/90533 [00:02<00:00, 33528.91 examples/s]Converting train dataset to ChatML:  85%|████████▌ | 77000/90533 [00:02<00:00, 33427.17 examples/s]Converting train dataset to ChatML:  89%|████████▉ | 80385/90533 [00:02<00:00, 33520.89 examples/s]Converting train dataset to ChatML:  94%|█████████▍| 85360/90533 [00:02<00:00, 33383.24 examples/s]Converting train dataset to ChatML:  98%|█████████▊| 88721/90533 [00:02<00:00, 33436.59 examples/s]Converting train dataset to ChatML: 100%|██████████| 90533/90533 [00:02<00:00, 32766.50 examples/s]
Applying chat template to train dataset:   0%|          | 0/90533 [00:00<?, ? examples/s]Applying chat template to train dataset:   2%|▏         | 1481/90533 [00:00<00:06, 14748.76 examples/s]Applying chat template to train dataset:   3%|▎         | 3000/90533 [00:00<00:05, 14972.60 examples/s]Applying chat template to train dataset:   5%|▍         | 4525/90533 [00:00<00:05, 15094.63 examples/s]Applying chat template to train dataset:   7%|▋         | 6040/90533 [00:00<00:05, 15111.18 examples/s]Applying chat template to train dataset:   8%|▊         | 7566/90533 [00:00<00:05, 15159.07 examples/s]Applying chat template to train dataset:  10%|█         | 9084/90533 [00:00<00:05, 15163.04 examples/s]Applying chat template to train dataset:  12%|█▏        | 10605/90533 [00:00<00:05, 15173.45 examples/s]Applying chat template to train dataset:  14%|█▍        | 12667/90533 [00:00<00:05, 14510.15 examples/s]Applying chat template to train dataset:  16%|█▋        | 14861/90533 [00:01<00:05, 14549.88 examples/s]Applying chat template to train dataset:  18%|█▊        | 16331/90533 [00:01<00:05, 14587.34 examples/s]Applying chat template to train dataset:  20%|█▉        | 17805/90533 [00:01<00:04, 14625.38 examples/s]Applying chat template to train dataset:  22%|██▏       | 20000/90533 [00:01<00:04, 14605.09 examples/s]Applying chat template to train dataset:  24%|██▎       | 21473/90533 [00:01<00:04, 14634.42 examples/s]Applying chat template to train dataset:  25%|██▌       | 22946/90533 [00:01<00:04, 14658.06 examples/s]Applying chat template to train dataset:  27%|██▋       | 24416/90533 [00:01<00:04, 14667.04 examples/s]Applying chat template to train dataset:  29%|██▊       | 25901/90533 [00:01<00:04, 14716.77 examples/s]Applying chat template to train dataset:  31%|███       | 28113/90533 [00:01<00:04, 14724.81 examples/s]Applying chat template to train dataset:  33%|███▎      | 29605/90533 [00:02<00:04, 14773.64 examples/s]Applying chat template to train dataset:  34%|███▍      | 31094/90533 [00:02<00:04, 14803.09 examples/s]Applying chat template to train dataset:  36%|███▌      | 32597/90533 [00:02<00:03, 14863.07 examples/s]Applying chat template to train dataset:  38%|███▊      | 34098/90533 [00:02<00:03, 14902.12 examples/s]Applying chat template to train dataset:  40%|███▉      | 36181/90533 [00:02<00:03, 14511.05 examples/s]Applying chat template to train dataset:  42%|████▏     | 38270/90533 [00:02<00:03, 14299.08 examples/s]Applying chat template to train dataset:  45%|████▍     | 40349/90533 [00:02<00:03, 14148.15 examples/s]Applying chat template to train dataset:  46%|████▌     | 41838/90533 [00:02<00:03, 14325.37 examples/s]Applying chat template to train dataset:  48%|████▊     | 43329/90533 [00:02<00:03, 14472.31 examples/s]Applying chat template to train dataset:  50%|████▉     | 44825/90533 [00:03<00:03, 14600.19 examples/s]Applying chat template to train dataset:  51%|█████     | 46308/90533 [00:03<00:03, 14662.87 examples/s]Applying chat template to train dataset:  53%|█████▎    | 47811/90533 [00:03<00:02, 14765.33 examples/s]Applying chat template to train dataset:  54%|█████▍    | 49299/90533 [00:03<00:02, 14794.42 examples/s]Applying chat template to train dataset:  56%|█████▌    | 50789/90533 [00:03<00:02, 14819.91 examples/s]Applying chat template to train dataset:  58%|█████▊    | 52275/90533 [00:03<00:02, 14828.80 examples/s]Applying chat template to train dataset:  60%|██████    | 54526/90533 [00:03<00:02, 14897.45 examples/s]Applying chat template to train dataset:  62%|██████▏   | 56016/90533 [00:03<00:02, 14894.64 examples/s]Applying chat template to train dataset:  64%|██████▎   | 57520/90533 [00:03<00:02, 14929.80 examples/s]Applying chat template to train dataset:  66%|██████▌   | 59768/90533 [00:04<00:02, 14947.93 examples/s]Applying chat template to train dataset:  68%|██████▊   | 62005/90533 [00:04<00:01, 14933.38 examples/s]Applying chat template to train dataset:  70%|███████   | 63510/90533 [00:04<00:01, 14960.04 examples/s]Applying chat template to train dataset:  73%|███████▎  | 65759/90533 [00:04<00:01, 14953.14 examples/s]Applying chat template to train dataset:  75%|███████▌  | 68000/90533 [00:04<00:01, 14938.81 examples/s]Applying chat template to train dataset:  77%|███████▋  | 69500/90533 [00:04<00:01, 14951.69 examples/s]Applying chat template to train dataset:  78%|███████▊  | 70996/90533 [00:04<00:01, 14952.84 examples/s]Applying chat template to train dataset:  81%|████████  | 73228/90533 [00:04<00:01, 14923.38 examples/s]Applying chat template to train dataset:  83%|████████▎ | 74727/90533 [00:05<00:01, 14938.28 examples/s]Applying chat template to train dataset:  84%|████████▍ | 76228/90533 [00:05<00:00, 14953.67 examples/s]Applying chat template to train dataset:  86%|████████▌ | 77740/90533 [00:05<00:00, 14996.86 examples/s]Applying chat template to train dataset:  88%|████████▊ | 79245/90533 [00:05<00:00, 15007.96 examples/s]Applying chat template to train dataset:  89%|████████▉ | 80762/90533 [00:05<00:00, 15042.56 examples/s]Applying chat template to train dataset:  92%|█████████▏| 83015/90533 [00:05<00:00, 15030.66 examples/s]Applying chat template to train dataset:  93%|█████████▎| 84534/90533 [00:05<00:00, 15070.02 examples/s]Applying chat template to train dataset:  96%|█████████▌| 86797/90533 [00:05<00:00, 15073.41 examples/s]Applying chat template to train dataset:  98%|█████████▊| 89056/90533 [00:06<00:00, 15064.12 examples/s]Applying chat template to train dataset: 100%|██████████| 90533/90533 [00:06<00:00, 14824.10 examples/s]
Tokenizing train dataset:   0%|          | 0/90533 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 658/90533 [00:00<00:13, 6553.15 examples/s]Tokenizing train dataset:   2%|▏         | 1606/90533 [00:00<00:13, 6384.44 examples/s]Tokenizing train dataset:   3%|▎         | 2548/90533 [00:00<00:13, 6327.47 examples/s]Tokenizing train dataset:   4%|▍         | 3499/90533 [00:00<00:13, 6328.70 examples/s]Tokenizing train dataset:   5%|▍         | 4459/90533 [00:00<00:13, 6350.01 examples/s]Tokenizing train dataset:   6%|▌         | 5409/90533 [00:00<00:13, 6339.08 examples/s]Tokenizing train dataset:   7%|▋         | 6346/90533 [00:01<00:13, 6304.89 examples/s]Tokenizing train dataset:   8%|▊         | 7000/90533 [00:01<00:13, 6256.94 examples/s]Tokenizing train dataset:   8%|▊         | 7671/90533 [00:01<00:13, 6368.13 examples/s]Tokenizing train dataset:   9%|▉         | 8335/90533 [00:01<00:13, 6317.46 examples/s]Tokenizing train dataset:  10%|▉         | 9000/90533 [00:01<00:12, 6295.21 examples/s]Tokenizing train dataset:  11%|█         | 9676/90533 [00:01<00:12, 6419.58 examples/s]Tokenizing train dataset:  11%|█▏        | 10330/90533 [00:01<00:12, 6330.09 examples/s]Tokenizing train dataset:  12%|█▏        | 10986/90533 [00:01<00:12, 6394.78 examples/s]Tokenizing train dataset:  13%|█▎        | 11882/90533 [00:01<00:12, 6231.97 examples/s]Tokenizing train dataset:  14%|█▍        | 12827/90533 [00:02<00:12, 6251.91 examples/s]Tokenizing train dataset:  15%|█▌        | 13778/90533 [00:02<00:12, 6277.61 examples/s]Tokenizing train dataset:  16%|█▋        | 14715/90533 [00:02<00:12, 6264.46 examples/s]Tokenizing train dataset:  17%|█▋        | 15671/90533 [00:02<00:11, 6268.77 examples/s]Tokenizing train dataset:  18%|█▊        | 16333/90533 [00:02<00:11, 6235.59 examples/s]Tokenizing train dataset:  19%|█▉        | 17000/90533 [00:02<00:11, 6256.60 examples/s]Tokenizing train dataset:  20%|█▉        | 17674/90533 [00:02<00:11, 6376.57 examples/s]Tokenizing train dataset:  20%|██        | 18342/90533 [00:02<00:11, 6315.97 examples/s]Tokenizing train dataset:  21%|██        | 19000/90533 [00:03<00:11, 6289.00 examples/s]Tokenizing train dataset:  22%|██▏       | 19678/90533 [00:03<00:11, 6422.35 examples/s]Tokenizing train dataset:  22%|██▏       | 20344/90533 [00:03<00:11, 6351.97 examples/s]Tokenizing train dataset:  23%|██▎       | 21000/90533 [00:03<00:11, 6312.07 examples/s]Tokenizing train dataset:  24%|██▍       | 21674/90533 [00:03<00:10, 6431.56 examples/s]Tokenizing train dataset:  25%|██▍       | 22342/90533 [00:03<00:10, 6370.69 examples/s]Tokenizing train dataset:  25%|██▌       | 23000/90533 [00:03<00:10, 6324.05 examples/s]Tokenizing train dataset:  26%|██▌       | 23679/90533 [00:03<00:10, 6453.51 examples/s]Tokenizing train dataset:  27%|██▋       | 24332/90533 [00:03<00:10, 6356.54 examples/s]Tokenizing train dataset:  28%|██▊       | 25000/90533 [00:03<00:10, 6314.22 examples/s]Tokenizing train dataset:  28%|██▊       | 25680/90533 [00:04<00:10, 6451.71 examples/s]Tokenizing train dataset:  29%|██▉       | 26342/90533 [00:04<00:10, 6381.04 examples/s]Tokenizing train dataset:  30%|██▉       | 27000/90533 [00:04<00:10, 6338.99 examples/s]Tokenizing train dataset:  31%|███       | 27686/90533 [00:04<00:09, 6485.47 examples/s]Tokenizing train dataset:  32%|███▏      | 28670/90533 [00:04<00:09, 6428.36 examples/s]Tokenizing train dataset:  32%|███▏      | 29337/90533 [00:04<00:09, 6356.43 examples/s]Tokenizing train dataset:  33%|███▎      | 30000/90533 [00:04<00:09, 6287.59 examples/s]Tokenizing train dataset:  34%|███▍      | 30669/90533 [00:04<00:09, 6396.18 examples/s]Tokenizing train dataset:  35%|███▍      | 31328/90533 [00:04<00:09, 6288.68 examples/s]Tokenizing train dataset:  35%|███▌      | 31986/90533 [00:05<00:09, 6368.39 examples/s]Tokenizing train dataset:  36%|███▌      | 32789/90533 [00:05<00:09, 5981.05 examples/s]Tokenizing train dataset:  37%|███▋      | 33404/90533 [00:05<00:09, 6023.40 examples/s]Tokenizing train dataset:  38%|███▊      | 34023/90533 [00:05<00:09, 6064.76 examples/s]Tokenizing train dataset:  38%|███▊      | 34713/90533 [00:05<00:08, 6296.69 examples/s]Tokenizing train dataset:  39%|███▉      | 35680/90533 [00:05<00:08, 6344.91 examples/s]Tokenizing train dataset:  40%|████      | 36343/90533 [00:05<00:08, 6323.63 examples/s]Tokenizing train dataset:  41%|████      | 37000/90533 [00:05<00:08, 6299.30 examples/s]Tokenizing train dataset:  42%|████▏     | 37676/90533 [00:05<00:08, 6423.85 examples/s]Tokenizing train dataset:  43%|████▎     | 38561/90533 [00:06<00:08, 6223.06 examples/s]Tokenizing train dataset:  43%|████▎     | 39191/90533 [00:06<00:08, 6240.83 examples/s]Tokenizing train dataset:  44%|████▍     | 39874/90533 [00:06<00:07, 6397.62 examples/s]Tokenizing train dataset:  45%|████▌     | 40835/90533 [00:06<00:07, 6396.54 examples/s]Tokenizing train dataset:  46%|████▌     | 41797/90533 [00:06<00:07, 6398.81 examples/s]Tokenizing train dataset:  47%|████▋     | 42679/90533 [00:06<00:07, 6222.01 examples/s]Tokenizing train dataset:  48%|████▊     | 43320/90533 [00:06<00:07, 6119.45 examples/s]Tokenizing train dataset:  49%|████▊     | 43992/90533 [00:06<00:07, 6265.79 examples/s]Tokenizing train dataset:  50%|████▉     | 44946/90533 [00:07<00:07, 6297.22 examples/s]Tokenizing train dataset:  51%|█████     | 45910/90533 [00:07<00:07, 6338.04 examples/s]Tokenizing train dataset:  52%|█████▏    | 46861/90533 [00:07<00:06, 6335.99 examples/s]Tokenizing train dataset:  53%|█████▎    | 47817/90533 [00:07<00:06, 6344.03 examples/s]Tokenizing train dataset:  54%|█████▍    | 48778/90533 [00:07<00:06, 6359.27 examples/s]Tokenizing train dataset:  55%|█████▍    | 49736/90533 [00:07<00:06, 6364.83 examples/s]Tokenizing train dataset:  56%|█████▌    | 50691/90533 [00:08<00:06, 6360.63 examples/s]Tokenizing train dataset:  57%|█████▋    | 51337/90533 [00:08<00:06, 6314.62 examples/s]Tokenizing train dataset:  57%|█████▋    | 52000/90533 [00:08<00:06, 6262.24 examples/s]Tokenizing train dataset:  58%|█████▊    | 52676/90533 [00:08<00:05, 6385.70 examples/s]Tokenizing train dataset:  59%|█████▉    | 53335/90533 [00:08<00:05, 6320.02 examples/s]Tokenizing train dataset:  60%|█████▉    | 54000/90533 [00:08<00:05, 6249.93 examples/s]Tokenizing train dataset:  60%|██████    | 54681/90533 [00:08<00:05, 6400.83 examples/s]Tokenizing train dataset:  61%|██████    | 55336/90533 [00:08<00:05, 6357.97 examples/s]Tokenizing train dataset:  62%|██████▏   | 56000/90533 [00:08<00:05, 6337.28 examples/s]Tokenizing train dataset:  63%|██████▎   | 56681/90533 [00:08<00:05, 6469.38 examples/s]Tokenizing train dataset:  63%|██████▎   | 57339/90533 [00:09<00:05, 6393.81 examples/s]Tokenizing train dataset:  64%|██████▍   | 58000/90533 [00:09<00:05, 6352.69 examples/s]Tokenizing train dataset:  65%|██████▍   | 58666/90533 [00:09<00:04, 6437.93 examples/s]Tokenizing train dataset:  66%|██████▌   | 59330/90533 [00:09<00:04, 6282.57 examples/s]Tokenizing train dataset:  66%|██████▋   | 60077/90533 [00:09<00:05, 5785.98 examples/s]Tokenizing train dataset:  67%|██████▋   | 60674/90533 [00:09<00:05, 5831.98 examples/s]Tokenizing train dataset:  68%|██████▊   | 61330/90533 [00:09<00:04, 5872.36 examples/s]Tokenizing train dataset:  68%|██████▊   | 61977/90533 [00:09<00:04, 6032.81 examples/s]Tokenizing train dataset:  69%|██████▉   | 62860/90533 [00:09<00:04, 5975.58 examples/s]Tokenizing train dataset:  70%|███████   | 63735/90533 [00:10<00:04, 5923.88 examples/s]Tokenizing train dataset:  71%|███████▏  | 64628/90533 [00:10<00:04, 5901.90 examples/s]Tokenizing train dataset:  72%|███████▏  | 65516/90533 [00:10<00:04, 5904.69 examples/s]Tokenizing train dataset:  73%|███████▎  | 66410/90533 [00:10<00:04, 5919.72 examples/s]Tokenizing train dataset:  74%|███████▍  | 67313/90533 [00:10<00:03, 5933.80 examples/s]Tokenizing train dataset:  75%|███████▌  | 67979/90533 [00:10<00:03, 6097.51 examples/s]Tokenizing train dataset:  76%|███████▌  | 68935/90533 [00:11<00:03, 6183.22 examples/s]Tokenizing train dataset:  77%|███████▋  | 69812/90533 [00:11<00:03, 6072.99 examples/s]Tokenizing train dataset:  78%|███████▊  | 70675/90533 [00:11<00:03, 5972.93 examples/s]Tokenizing train dataset:  79%|███████▉  | 71550/90533 [00:11<00:03, 5926.17 examples/s]Tokenizing train dataset:  80%|████████  | 72458/90533 [00:11<00:03, 5962.18 examples/s]Tokenizing train dataset:  81%|████████  | 73060/90533 [00:11<00:02, 5974.33 examples/s]Tokenizing train dataset:  81%|████████▏ | 73721/90533 [00:11<00:02, 6128.99 examples/s]Tokenizing train dataset:  82%|████████▏ | 74666/90533 [00:11<00:02, 6157.16 examples/s]Tokenizing train dataset:  83%|████████▎ | 75326/90533 [00:12<00:02, 6132.39 examples/s]Tokenizing train dataset:  84%|████████▍ | 75989/90533 [00:12<00:02, 6255.60 examples/s]Tokenizing train dataset:  85%|████████▍ | 76906/90533 [00:12<00:02, 6200.36 examples/s]Tokenizing train dataset:  86%|████████▌ | 77836/90533 [00:12<00:02, 6195.37 examples/s]Tokenizing train dataset:  87%|████████▋ | 78751/90533 [00:12<00:01, 6160.24 examples/s]Tokenizing train dataset:  88%|████████▊ | 79668/90533 [00:12<00:01, 6137.43 examples/s]Tokenizing train dataset:  89%|████████▉ | 80587/90533 [00:12<00:01, 6130.46 examples/s]Tokenizing train dataset:  90%|█████████ | 81512/90533 [00:13<00:01, 6139.22 examples/s]Tokenizing train dataset:  91%|█████████ | 82430/90533 [00:13<00:01, 6130.57 examples/s]Tokenizing train dataset:  92%|█████████▏| 83342/90533 [00:13<00:01, 6113.11 examples/s]Tokenizing train dataset:  93%|█████████▎| 84000/90533 [00:13<00:01, 6086.56 examples/s]Tokenizing train dataset:  94%|█████████▎| 84663/90533 [00:13<00:00, 6214.72 examples/s]Tokenizing train dataset:  95%|█████████▍| 85583/90533 [00:13<00:00, 6184.26 examples/s]Tokenizing train dataset:  96%|█████████▌| 86496/90533 [00:13<00:00, 6148.58 examples/s]Tokenizing train dataset:  96%|█████████▌| 87117/90533 [00:13<00:00, 6162.32 examples/s]Tokenizing train dataset:  97%|█████████▋| 87793/90533 [00:14<00:00, 6311.09 examples/s]Tokenizing train dataset:  98%|█████████▊| 88748/90533 [00:14<00:00, 6328.06 examples/s]Tokenizing train dataset:  99%|█████████▉| 89453/90533 [00:14<00:00, 5479.83 examples/s]Tokenizing train dataset:  99%|█████████▉| 90056/90533 [00:14<00:00, 5606.07 examples/s]Tokenizing train dataset: 100%|██████████| 90533/90533 [00:14<00:00, 6209.30 examples/s]
Truncating train dataset:   0%|          | 0/90533 [00:00<?, ? examples/s]Truncating train dataset: 100%|██████████| 90533/90533 [00:00<00:00, 3298467.91 examples/s]
Converting eval dataset to ChatML:   0%|          | 0/30000 [00:00<?, ? examples/s]Converting eval dataset to ChatML:  11%|█▏        | 3381/30000 [00:00<00:00, 33708.77 examples/s]Converting eval dataset to ChatML:  23%|██▎       | 6810/30000 [00:00<00:00, 34045.78 examples/s]Converting eval dataset to ChatML:  40%|███▉      | 11900/30000 [00:00<00:00, 33975.94 examples/s]Converting eval dataset to ChatML:  57%|█████▋    | 16991/30000 [00:00<00:00, 33954.31 examples/s]Converting eval dataset to ChatML:  73%|███████▎  | 22034/30000 [00:00<00:00, 33820.36 examples/s]Converting eval dataset to ChatML:  85%|████████▍ | 25438/30000 [00:00<00:00, 33877.12 examples/s]Converting eval dataset to ChatML:  96%|█████████▌| 28861/30000 [00:00<00:00, 33972.07 examples/s]Converting eval dataset to ChatML: 100%|██████████| 30000/30000 [00:00<00:00, 33835.75 examples/s]
Applying chat template to eval dataset:   0%|          | 0/30000 [00:00<?, ? examples/s]Applying chat template to eval dataset:   5%|▌         | 1516/30000 [00:00<00:01, 15094.34 examples/s]Applying chat template to eval dataset:  10%|█         | 3027/30000 [00:00<00:01, 15096.78 examples/s]Applying chat template to eval dataset:  15%|█▌        | 4549/30000 [00:00<00:01, 15149.10 examples/s]Applying chat template to eval dataset:  20%|██        | 6068/30000 [00:00<00:01, 15161.97 examples/s]Applying chat template to eval dataset:  25%|██▌       | 7597/30000 [00:00<00:01, 15203.38 examples/s]Applying chat template to eval dataset:  33%|███▎      | 9880/30000 [00:00<00:01, 15208.75 examples/s]Applying chat template to eval dataset:  40%|████      | 12150/30000 [00:00<00:01, 15174.71 examples/s]Applying chat template to eval dataset:  46%|████▌     | 13673/30000 [00:00<00:01, 15185.47 examples/s]Applying chat template to eval dataset:  53%|█████▎    | 15956/30000 [00:01<00:00, 15195.19 examples/s]Applying chat template to eval dataset:  58%|█████▊    | 17476/30000 [00:01<00:00, 15193.83 examples/s]Applying chat template to eval dataset:  63%|██████▎   | 19000/30000 [00:01<00:00, 15185.82 examples/s]Applying chat template to eval dataset:  68%|██████▊   | 20520/30000 [00:01<00:00, 15188.30 examples/s]Applying chat template to eval dataset:  76%|███████▌  | 22796/30000 [00:01<00:00, 15182.16 examples/s]Applying chat template to eval dataset:  81%|████████  | 24315/30000 [00:01<00:00, 15182.73 examples/s]Applying chat template to eval dataset:  86%|████████▌ | 25844/30000 [00:01<00:00, 15207.17 examples/s]Applying chat template to eval dataset:  94%|█████████▎| 28111/30000 [00:01<00:00, 15168.62 examples/s]Applying chat template to eval dataset:  99%|█████████▉| 29633/30000 [00:01<00:00, 15178.59 examples/s]Applying chat template to eval dataset: 100%|██████████| 30000/30000 [00:01<00:00, 15171.20 examples/s]
Tokenizing eval dataset:   0%|          | 0/30000 [00:00<?, ? examples/s]Tokenizing eval dataset:   2%|▏         | 679/30000 [00:00<00:04, 6761.44 examples/s]Tokenizing eval dataset:   6%|▌         | 1674/30000 [00:00<00:04, 6442.58 examples/s]Tokenizing eval dataset:   8%|▊         | 2334/30000 [00:00<00:04, 6294.41 examples/s]Tokenizing eval dataset:  10%|█         | 3000/30000 [00:00<00:04, 6270.47 examples/s]Tokenizing eval dataset:  12%|█▏        | 3669/30000 [00:00<00:04, 6405.39 examples/s]Tokenizing eval dataset:  14%|█▍        | 4341/30000 [00:00<00:04, 6309.98 examples/s]Tokenizing eval dataset:  17%|█▋        | 5000/30000 [00:00<00:03, 6277.17 examples/s]Tokenizing eval dataset:  19%|█▉        | 5675/30000 [00:00<00:03, 6417.15 examples/s]Tokenizing eval dataset:  22%|██▏       | 6567/30000 [00:01<00:03, 6227.84 examples/s]Tokenizing eval dataset:  25%|██▌       | 7516/30000 [00:01<00:03, 6260.85 examples/s]Tokenizing eval dataset:  28%|██▊       | 8467/30000 [00:01<00:03, 6286.54 examples/s]Tokenizing eval dataset:  31%|███▏      | 9424/30000 [00:01<00:03, 6313.19 examples/s]Tokenizing eval dataset:  35%|███▍      | 10371/30000 [00:01<00:03, 6308.29 examples/s]Tokenizing eval dataset:  38%|███▊      | 11338/30000 [00:01<00:02, 6321.06 examples/s]Tokenizing eval dataset:  40%|████      | 12000/30000 [00:01<00:02, 6288.51 examples/s]Tokenizing eval dataset:  42%|████▏     | 12682/30000 [00:02<00:02, 6414.70 examples/s]Tokenizing eval dataset:  44%|████▍     | 13341/30000 [00:02<00:02, 6365.04 examples/s]Tokenizing eval dataset:  47%|████▋     | 14000/30000 [00:02<00:02, 6353.58 examples/s]Tokenizing eval dataset:  49%|████▉     | 14686/30000 [00:02<00:02, 6488.40 examples/s]Tokenizing eval dataset:  51%|█████     | 15338/30000 [00:02<00:02, 6420.41 examples/s]Tokenizing eval dataset:  53%|█████▎    | 16000/30000 [00:02<00:02, 6348.97 examples/s]Tokenizing eval dataset:  56%|█████▌    | 16680/30000 [00:02<00:02, 6473.85 examples/s]Tokenizing eval dataset:  58%|█████▊    | 17340/30000 [00:02<00:01, 6405.13 examples/s]Tokenizing eval dataset:  60%|██████    | 18000/30000 [00:02<00:01, 6340.58 examples/s]Tokenizing eval dataset:  62%|██████▏   | 18670/30000 [00:02<00:01, 6443.39 examples/s]Tokenizing eval dataset:  64%|██████▍   | 19340/30000 [00:03<00:01, 6366.80 examples/s]Tokenizing eval dataset:  67%|██████▋   | 20000/30000 [00:03<00:01, 6303.40 examples/s]Tokenizing eval dataset:  69%|██████▉   | 20676/30000 [00:03<00:01, 6432.25 examples/s]Tokenizing eval dataset:  71%|███████   | 21340/30000 [00:03<00:01, 6368.72 examples/s]Tokenizing eval dataset:  73%|███████▎  | 22000/30000 [00:03<00:01, 6318.13 examples/s]Tokenizing eval dataset:  76%|███████▌  | 22679/30000 [00:03<00:01, 6451.70 examples/s]Tokenizing eval dataset:  78%|███████▊  | 23338/30000 [00:03<00:01, 6355.23 examples/s]Tokenizing eval dataset:  80%|████████  | 24000/30000 [00:03<00:00, 6306.18 examples/s]Tokenizing eval dataset:  82%|████████▏ | 24677/30000 [00:03<00:00, 6436.69 examples/s]Tokenizing eval dataset:  84%|████████▍ | 25338/30000 [00:03<00:00, 6373.35 examples/s]Tokenizing eval dataset:  87%|████████▋ | 26000/30000 [00:04<00:00, 6304.65 examples/s]Tokenizing eval dataset:  89%|████████▉ | 26680/30000 [00:04<00:00, 6445.08 examples/s]Tokenizing eval dataset:  91%|█████████ | 27343/30000 [00:04<00:00, 6376.28 examples/s]Tokenizing eval dataset:  93%|█████████▎| 28000/30000 [00:04<00:00, 6281.10 examples/s]Tokenizing eval dataset:  96%|█████████▌| 28680/30000 [00:04<00:00, 6427.00 examples/s]Tokenizing eval dataset:  98%|█████████▊| 29328/30000 [00:04<00:00, 6326.39 examples/s]Tokenizing eval dataset: 100%|██████████| 30000/30000 [00:04<00:00, 6287.45 examples/s]Tokenizing eval dataset: 100%|██████████| 30000/30000 [00:04<00:00, 6352.13 examples/s]
Truncating eval dataset:   0%|          | 0/30000 [00:00<?, ? examples/s]Truncating eval dataset: 100%|██████████| 30000/30000 [00:00<00:00, 2961242.59 examples/s]
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.
{'loss': 2.6535, 'grad_norm': 2.701695442199707, 'learning_rate': 0.0019556444444444447, 'epoch': 0.04418132013784572}
{'eval_loss': 2.3192741870880127, 'eval_runtime': 48.2831, 'eval_samples_per_second': 621.336, 'eval_steps_per_second': 77.667, 'eval_num_tokens': 278008.0, 'eval_mean_token_accuracy': 0.6416160613218943, 'epoch': 0.04418132013784572}
{'loss': 2.304, 'grad_norm': 1.5755444765090942, 'learning_rate': 0.0019112, 'epoch': 0.08836264027569143}
{'eval_loss': 2.1995558738708496, 'eval_runtime': 48.4637, 'eval_samples_per_second': 619.019, 'eval_steps_per_second': 77.377, 'eval_num_tokens': 555997.0, 'eval_mean_token_accuracy': 0.6559107581615448, 'epoch': 0.08836264027569143}
{'loss': 2.1986, 'grad_norm': 1.090477705001831, 'learning_rate': 0.0018667555555555554, 'epoch': 0.13254396041353717}
{'eval_loss': 2.1075477600097656, 'eval_runtime': 48.5172, 'eval_samples_per_second': 618.337, 'eval_steps_per_second': 77.292, 'eval_num_tokens': 834897.0, 'eval_mean_token_accuracy': 0.6663704367876053, 'epoch': 0.13254396041353717}
{'loss': 2.1362, 'grad_norm': 0.9301804304122925, 'learning_rate': 0.0018223111111111113, 'epoch': 0.17672528055138287}
{'eval_loss': 2.0550425052642822, 'eval_runtime': 48.6338, 'eval_samples_per_second': 616.855, 'eval_steps_per_second': 77.107, 'eval_num_tokens': 1115905.0, 'eval_mean_token_accuracy': 0.6719644823312759, 'epoch': 0.17672528055138287}
{'loss': 2.0759, 'grad_norm': 1.2591620683670044, 'learning_rate': 0.0017778666666666667, 'epoch': 0.2209066006892286}
{'eval_loss': 2.033815383911133, 'eval_runtime': 49.6479, 'eval_samples_per_second': 604.256, 'eval_steps_per_second': 75.532, 'eval_num_tokens': 1393839.0, 'eval_mean_token_accuracy': 0.67448871336778, 'epoch': 0.2209066006892286}
{'loss': 2.0244, 'grad_norm': 1.5680843591690063, 'learning_rate': 0.0017334222222222223, 'epoch': 0.26508792082707433}
{'eval_loss': 1.9854133129119873, 'eval_runtime': 49.2177, 'eval_samples_per_second': 609.537, 'eval_steps_per_second': 76.192, 'eval_num_tokens': 1675040.0, 'eval_mean_token_accuracy': 0.6799553528467814, 'epoch': 0.26508792082707433}
{'loss': 1.9871, 'grad_norm': 1.27925443649292, 'learning_rate': 0.0016889777777777777, 'epoch': 0.30926924096492003}
{'eval_loss': 1.943976640701294, 'eval_runtime': 48.9553, 'eval_samples_per_second': 612.804, 'eval_steps_per_second': 76.6, 'eval_num_tokens': 1953445.0, 'eval_mean_token_accuracy': 0.6852287560383479, 'epoch': 0.30926924096492003}
{'loss': 1.9388, 'grad_norm': 1.7538267374038696, 'learning_rate': 0.0016445333333333335, 'epoch': 0.35345056110276574}
{'eval_loss': 1.9125585556030273, 'eval_runtime': 48.7387, 'eval_samples_per_second': 615.528, 'eval_steps_per_second': 76.941, 'eval_num_tokens': 2231561.0, 'eval_mean_token_accuracy': 0.6891176415046056, 'epoch': 0.35345056110276574}
{'loss': 1.9442, 'grad_norm': 1.0701032876968384, 'learning_rate': 0.0016000888888888889, 'epoch': 0.3976318812406115}
{'eval_loss': 1.8911375999450684, 'eval_runtime': 48.7865, 'eval_samples_per_second': 614.924, 'eval_steps_per_second': 76.866, 'eval_num_tokens': 2513499.0, 'eval_mean_token_accuracy': 0.689840367102623, 'epoch': 0.3976318812406115}
{'loss': 1.9033, 'grad_norm': 1.6748731136322021, 'learning_rate': 0.0015556444444444445, 'epoch': 0.4418132013784572}
{'eval_loss': 1.869073748588562, 'eval_runtime': 48.8424, 'eval_samples_per_second': 614.221, 'eval_steps_per_second': 76.778, 'eval_num_tokens': 2790751.0, 'eval_mean_token_accuracy': 0.6921871220986049, 'epoch': 0.4418132013784572}
{'loss': 1.8826, 'grad_norm': 0.8019850254058838, 'learning_rate': 0.0015112, 'epoch': 0.4859945215163029}
{'eval_loss': 1.842150092124939, 'eval_runtime': 48.8789, 'eval_samples_per_second': 613.762, 'eval_steps_per_second': 76.72, 'eval_num_tokens': 3069649.0, 'eval_mean_token_accuracy': 0.6947623234272003, 'epoch': 0.4859945215163029}
{'loss': 1.8365, 'grad_norm': 1.5993261337280273, 'learning_rate': 0.0014667555555555557, 'epoch': 0.5301758416541487}
{'eval_loss': 1.8213233947753906, 'eval_runtime': 48.9626, 'eval_samples_per_second': 612.712, 'eval_steps_per_second': 76.589, 'eval_num_tokens': 3349122.0, 'eval_mean_token_accuracy': 0.6977881124416987, 'epoch': 0.5301758416541487}
{'loss': 1.8226, 'grad_norm': 1.0238250494003296, 'learning_rate': 0.001422311111111111, 'epoch': 0.5743571617919944}
{'eval_loss': 1.810745358467102, 'eval_runtime': 48.7288, 'eval_samples_per_second': 615.653, 'eval_steps_per_second': 76.957, 'eval_num_tokens': 3628449.0, 'eval_mean_token_accuracy': 0.6990219099601109, 'epoch': 0.5743571617919944}
{'loss': 1.8259, 'grad_norm': 0.9906859397888184, 'learning_rate': 0.0013778666666666667, 'epoch': 0.6185384819298401}
{'eval_loss': 1.7909270524978638, 'eval_runtime': 48.7254, 'eval_samples_per_second': 615.696, 'eval_steps_per_second': 76.962, 'eval_num_tokens': 3906560.0, 'eval_mean_token_accuracy': 0.6996126596609752, 'epoch': 0.6185384819298401}
{'loss': 1.8169, 'grad_norm': 1.8006629943847656, 'learning_rate': 0.0013334222222222223, 'epoch': 0.6627198020676858}
{'eval_loss': 1.7869373559951782, 'eval_runtime': 48.6625, 'eval_samples_per_second': 616.491, 'eval_steps_per_second': 77.061, 'eval_num_tokens': 4182637.0, 'eval_mean_token_accuracy': 0.7009318333864212, 'epoch': 0.6627198020676858}
{'loss': 1.7852, 'grad_norm': 0.9350388050079346, 'learning_rate': 0.001288977777777778, 'epoch': 0.7069011222055315}
{'eval_loss': 1.7580301761627197, 'eval_runtime': 48.8116, 'eval_samples_per_second': 614.609, 'eval_steps_per_second': 76.826, 'eval_num_tokens': 4459892.0, 'eval_mean_token_accuracy': 0.7045080132484436, 'epoch': 0.7069011222055315}
{'loss': 1.7667, 'grad_norm': 0.6476531624794006, 'learning_rate': 0.0012445333333333333, 'epoch': 0.7510824423433772}
{'eval_loss': 1.7477085590362549, 'eval_runtime': 48.4998, 'eval_samples_per_second': 618.559, 'eval_steps_per_second': 77.32, 'eval_num_tokens': 4740296.0, 'eval_mean_token_accuracy': 0.7053487269322077, 'epoch': 0.7510824423433772}
{'loss': 1.7723, 'grad_norm': 0.9572727680206299, 'learning_rate': 0.001200088888888889, 'epoch': 0.795263762481223}
{'eval_loss': 1.7449101209640503, 'eval_runtime': 48.5589, 'eval_samples_per_second': 617.807, 'eval_steps_per_second': 77.226, 'eval_num_tokens': 5018897.0, 'eval_mean_token_accuracy': 0.7049435410896937, 'epoch': 0.795263762481223}
{'loss': 1.7514, 'grad_norm': 1.260791540145874, 'learning_rate': 0.0011556444444444445, 'epoch': 0.8394450826190687}
{'eval_loss': 1.7320151329040527, 'eval_runtime': 48.6104, 'eval_samples_per_second': 617.152, 'eval_steps_per_second': 77.144, 'eval_num_tokens': 5296435.0, 'eval_mean_token_accuracy': 0.7070884853204091, 'epoch': 0.8394450826190687}
{'loss': 1.7483, 'grad_norm': 0.7285470962524414, 'learning_rate': 0.0011112, 'epoch': 0.8836264027569144}
{'eval_loss': 1.7121515274047852, 'eval_runtime': 48.6685, 'eval_samples_per_second': 616.415, 'eval_steps_per_second': 77.052, 'eval_num_tokens': 5575248.0, 'eval_mean_token_accuracy': 0.7084344969590505, 'epoch': 0.8836264027569144}
{'loss': 1.7192, 'grad_norm': 0.6942562460899353, 'learning_rate': 0.0010667555555555555, 'epoch': 0.9278077228947601}
{'eval_loss': 1.7024641036987305, 'eval_runtime': 48.6694, 'eval_samples_per_second': 616.403, 'eval_steps_per_second': 77.05, 'eval_num_tokens': 5854364.0, 'eval_mean_token_accuracy': 0.7097437565962473, 'epoch': 0.9278077228947601}
{'loss': 1.709, 'grad_norm': 0.9340904951095581, 'learning_rate': 0.0010223111111111111, 'epoch': 0.9719890430326058}
{'eval_loss': 1.6948059797286987, 'eval_runtime': 48.6431, 'eval_samples_per_second': 616.737, 'eval_steps_per_second': 77.092, 'eval_num_tokens': 6131875.0, 'eval_mean_token_accuracy': 0.711253716524442, 'epoch': 0.9719890430326058}
{'loss': 1.6552, 'grad_norm': 0.4987221360206604, 'learning_rate': 0.0009778666666666667, 'epoch': 1.0161703631704515}
{'eval_loss': 1.6866388320922852, 'eval_runtime': 48.6345, 'eval_samples_per_second': 616.846, 'eval_steps_per_second': 77.106, 'eval_num_tokens': 6408517.0, 'eval_mean_token_accuracy': 0.7125646873394649, 'epoch': 1.0161703631704515}
{'loss': 1.5627, 'grad_norm': 0.853569507598877, 'learning_rate': 0.0009334222222222223, 'epoch': 1.0603516833082973}
{'eval_loss': 1.6823217868804932, 'eval_runtime': 49.0017, 'eval_samples_per_second': 612.224, 'eval_steps_per_second': 76.528, 'eval_num_tokens': 6687494.0, 'eval_mean_token_accuracy': 0.7133185084581375, 'epoch': 1.0603516833082973}
{'loss': 1.5686, 'grad_norm': 1.0216914415359497, 'learning_rate': 0.0008889777777777777, 'epoch': 1.104533003446143}
{'eval_loss': 1.6786702871322632, 'eval_runtime': 49.3948, 'eval_samples_per_second': 607.351, 'eval_steps_per_second': 75.919, 'eval_num_tokens': 6966396.0, 'eval_mean_token_accuracy': 0.7138993854522705, 'epoch': 1.104533003446143}
{'loss': 1.5756, 'grad_norm': 0.7390801906585693, 'learning_rate': 0.0008445333333333333, 'epoch': 1.1487143235839887}
{'eval_loss': 1.6620622873306274, 'eval_runtime': 48.9253, 'eval_samples_per_second': 613.179, 'eval_steps_per_second': 76.647, 'eval_num_tokens': 7246454.0, 'eval_mean_token_accuracy': 0.7146144875367483, 'epoch': 1.1487143235839887}
{'loss': 1.5497, 'grad_norm': 0.9101086854934692, 'learning_rate': 0.0008000888888888888, 'epoch': 1.1928956437218343}
{'eval_loss': 1.6578929424285889, 'eval_runtime': 48.9333, 'eval_samples_per_second': 613.079, 'eval_steps_per_second': 76.635, 'eval_num_tokens': 7524428.0, 'eval_mean_token_accuracy': 0.7157663346290588, 'epoch': 1.1928956437218343}
{'loss': 1.5438, 'grad_norm': 0.645168662071228, 'learning_rate': 0.0007556444444444444, 'epoch': 1.2370769638596801}
{'eval_loss': 1.6469680070877075, 'eval_runtime': 48.8156, 'eval_samples_per_second': 614.557, 'eval_steps_per_second': 76.82, 'eval_num_tokens': 7803230.0, 'eval_mean_token_accuracy': 0.7171167468468348, 'epoch': 1.2370769638596801}
{'loss': 1.5502, 'grad_norm': 0.450739324092865, 'learning_rate': 0.0007112, 'epoch': 1.2812582839975257}
{'eval_loss': 1.641642451286316, 'eval_runtime': 48.9016, 'eval_samples_per_second': 613.477, 'eval_steps_per_second': 76.685, 'eval_num_tokens': 8080190.0, 'eval_mean_token_accuracy': 0.7179881954749425, 'epoch': 1.2812582839975257}
{'loss': 1.5319, 'grad_norm': 0.9534133076667786, 'learning_rate': 0.0006667555555555555, 'epoch': 1.3254396041353715}
{'eval_loss': 1.6292246580123901, 'eval_runtime': 48.8572, 'eval_samples_per_second': 614.034, 'eval_steps_per_second': 76.754, 'eval_num_tokens': 8358320.0, 'eval_mean_token_accuracy': 0.7195807615439097, 'epoch': 1.3254396041353715}
{'loss': 1.5116, 'grad_norm': 1.1817954778671265, 'learning_rate': 0.0006223111111111112, 'epoch': 1.3696209242732174}
{'eval_loss': 1.6191502809524536, 'eval_runtime': 48.7945, 'eval_samples_per_second': 614.824, 'eval_steps_per_second': 76.853, 'eval_num_tokens': 8636875.0, 'eval_mean_token_accuracy': 0.7203510098377863, 'epoch': 1.3696209242732174}
{'loss': 1.5142, 'grad_norm': 0.6845747828483582, 'learning_rate': 0.0005778666666666667, 'epoch': 1.413802244411063}
{'eval_loss': 1.6157768964767456, 'eval_runtime': 48.9096, 'eval_samples_per_second': 613.377, 'eval_steps_per_second': 76.672, 'eval_num_tokens': 8916058.0, 'eval_mean_token_accuracy': 0.7207126181681951, 'epoch': 1.413802244411063}
{'loss': 1.5101, 'grad_norm': 0.5417422652244568, 'learning_rate': 0.0005334222222222223, 'epoch': 1.4579835645489088}
{'eval_loss': 1.6096736192703247, 'eval_runtime': 49.0169, 'eval_samples_per_second': 612.034, 'eval_steps_per_second': 76.504, 'eval_num_tokens': 9192359.0, 'eval_mean_token_accuracy': 0.7215880236784618, 'epoch': 1.4579835645489088}
{'loss': 1.4992, 'grad_norm': 0.6339215636253357, 'learning_rate': 0.0004889777777777778, 'epoch': 1.5021648846867546}
{'eval_loss': 1.5989210605621338, 'eval_runtime': 48.8897, 'eval_samples_per_second': 613.626, 'eval_steps_per_second': 76.703, 'eval_num_tokens': 9471656.0, 'eval_mean_token_accuracy': 0.7230473941961925, 'epoch': 1.5021648846867546}
{'loss': 1.4849, 'grad_norm': 0.5981170535087585, 'learning_rate': 0.00044453333333333337, 'epoch': 1.5463462048246002}
{'eval_loss': 1.5923739671707153, 'eval_runtime': 48.6396, 'eval_samples_per_second': 616.781, 'eval_steps_per_second': 77.098, 'eval_num_tokens': 9749610.0, 'eval_mean_token_accuracy': 0.7232739447434743, 'epoch': 1.5463462048246002}
{'loss': 1.4821, 'grad_norm': 0.6587756276130676, 'learning_rate': 0.00040008888888888887, 'epoch': 1.5905275249624458}
{'eval_loss': 1.5856930017471313, 'eval_runtime': 48.6712, 'eval_samples_per_second': 616.381, 'eval_steps_per_second': 77.048, 'eval_num_tokens': 10025659.0, 'eval_mean_token_accuracy': 0.724613007680575, 'epoch': 1.5905275249624458}
{'loss': 1.493, 'grad_norm': 0.5008242130279541, 'learning_rate': 0.0003556444444444444, 'epoch': 1.6347088451002916}
{'eval_loss': 1.5781726837158203, 'eval_runtime': 48.545, 'eval_samples_per_second': 617.983, 'eval_steps_per_second': 77.248, 'eval_num_tokens': 10304939.0, 'eval_mean_token_accuracy': 0.7252850515286128, 'epoch': 1.6347088451002916}
{'loss': 1.4922, 'grad_norm': 0.4617614448070526, 'learning_rate': 0.0003112, 'epoch': 1.6788901652381374}
{'eval_loss': 1.5716801881790161, 'eval_runtime': 48.5903, 'eval_samples_per_second': 617.408, 'eval_steps_per_second': 77.176, 'eval_num_tokens': 10585850.0, 'eval_mean_token_accuracy': 0.7262559456268947, 'epoch': 1.6788901652381374}
{'loss': 1.475, 'grad_norm': 0.4479135274887085, 'learning_rate': 0.0002667555555555556, 'epoch': 1.723071485375983}
{'eval_loss': 1.5648342370986938, 'eval_runtime': 48.6242, 'eval_samples_per_second': 616.977, 'eval_steps_per_second': 77.122, 'eval_num_tokens': 10863421.0, 'eval_mean_token_accuracy': 0.7267549155473709, 'epoch': 1.723071485375983}
{'loss': 1.4758, 'grad_norm': 0.6496378779411316, 'learning_rate': 0.0002223111111111111, 'epoch': 1.7672528055138288}
{'eval_loss': 1.5585397481918335, 'eval_runtime': 49.5255, 'eval_samples_per_second': 605.749, 'eval_steps_per_second': 75.719, 'eval_num_tokens': 11142271.0, 'eval_mean_token_accuracy': 0.7278921517848969, 'epoch': 1.7672528055138288}
{'loss': 1.459, 'grad_norm': 0.5115048289299011, 'learning_rate': 0.0001778666666666667, 'epoch': 1.8114341256516746}
{'eval_loss': 1.5531964302062988, 'eval_runtime': 49.3131, 'eval_samples_per_second': 608.358, 'eval_steps_per_second': 76.045, 'eval_num_tokens': 11420134.0, 'eval_mean_token_accuracy': 0.728543499827385, 'epoch': 1.8114341256516746}
{'loss': 1.4572, 'grad_norm': 0.45092111825942993, 'learning_rate': 0.00013342222222222222, 'epoch': 1.8556154457895202}
{'eval_loss': 1.545457124710083, 'eval_runtime': 48.9734, 'eval_samples_per_second': 612.578, 'eval_steps_per_second': 76.572, 'eval_num_tokens': 11698971.0, 'eval_mean_token_accuracy': 0.7293026279687882, 'epoch': 1.8556154457895202}
{'loss': 1.4474, 'grad_norm': 0.5784002542495728, 'learning_rate': 8.897777777777778e-05, 'epoch': 1.8997967659273658}
{'eval_loss': 1.542062520980835, 'eval_runtime': 48.9078, 'eval_samples_per_second': 613.399, 'eval_steps_per_second': 76.675, 'eval_num_tokens': 11977234.0, 'eval_mean_token_accuracy': 0.7299096767346064, 'epoch': 1.8997967659273658}
{'loss': 1.453, 'grad_norm': 0.6865234375, 'learning_rate': 4.4533333333333336e-05, 'epoch': 1.9439780860652116}
{'eval_loss': 1.5390691757202148, 'eval_runtime': 48.892, 'eval_samples_per_second': 613.597, 'eval_steps_per_second': 76.7, 'eval_num_tokens': 12260361.0, 'eval_mean_token_accuracy': 0.7302926729440689, 'epoch': 1.9439780860652116}
{'loss': 1.4311, 'grad_norm': 0.44307610392570496, 'learning_rate': 8.88888888888889e-08, 'epoch': 1.9881594062030574}
{'eval_loss': 1.5371308326721191, 'eval_runtime': 48.5484, 'eval_samples_per_second': 617.94, 'eval_steps_per_second': 77.242, 'eval_num_tokens': 12539434.0, 'eval_mean_token_accuracy': 0.7305207407077153, 'epoch': 1.9881594062030574}
There were missing keys in the checkpoint model loaded: ['lm_head.weight'].
{'train_runtime': 3432.6006, 'train_samples_per_second': 52.438, 'train_steps_per_second': 6.555, 'train_loss': 1.7183581705729167, 'num_tokens': 12539434.0, 'mean_token_accuracy': 0.7023690482152833, 'epoch': 1.9881594062030574}
Time taken by training: 57.21 minutes
model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]model.safetensors:   1%|          | 2.95M/498M [00:00<00:16, 29.4MB/s]model.safetensors:   3%|▎         | 16.0M/498M [00:00<00:22, 21.8MB/s]model.safetensors:   6%|▋         | 32.0M/498M [00:01<00:13, 34.6MB/s]model.safetensors:  10%|▉         | 48.0M/498M [00:01<00:09, 46.9MB/s]model.safetensors:  13%|█▎        | 64.0M/498M [00:01<00:09, 47.3MB/s]model.safetensors:  16%|█▌        | 80.0M/498M [00:01<00:08, 49.5MB/s]model.safetensors:  19%|█▉        | 96.0M/498M [00:02<00:08, 46.0MB/s]model.safetensors:  23%|██▎       | 112M/498M [00:02<00:07, 49.0MB/s] model.safetensors:  26%|██▌       | 128M/498M [00:02<00:07, 52.5MB/s]model.safetensors:  29%|██▉       | 144M/498M [00:03<00:06, 54.4MB/s]model.safetensors:  32%|███▏      | 160M/498M [00:03<00:05, 57.8MB/s]model.safetensors:  35%|███▌      | 176M/498M [00:04<00:09, 35.1MB/s]model.safetensors:  39%|███▊      | 192M/498M [00:04<00:07, 39.3MB/s]model.safetensors:  42%|████▏     | 208M/498M [00:04<00:06, 43.2MB/s]model.safetensors:  45%|████▌     | 224M/498M [00:04<00:05, 50.0MB/s]model.safetensors:  48%|████▊     | 240M/498M [00:06<00:08, 28.9MB/s]model.safetensors:  51%|█████     | 254M/498M [00:06<00:06, 36.9MB/s]model.safetensors:  53%|█████▎    | 262M/498M [00:07<00:10, 22.1MB/s]model.safetensors:  55%|█████▍    | 272M/498M [00:07<00:09, 25.0MB/s]model.safetensors:  58%|█████▊    | 288M/498M [00:11<00:23, 9.09MB/s]model.safetensors:  60%|██████    | 301M/498M [00:11<00:15, 12.4MB/s]model.safetensors:  62%|██████▏   | 307M/498M [00:11<00:14, 13.3MB/s]model.safetensors:  64%|██████▍   | 320M/498M [00:11<00:10, 16.9MB/s]model.safetensors:  68%|██████▊   | 336M/498M [00:12<00:09, 17.3MB/s]model.safetensors:  71%|███████   | 352M/498M [00:13<00:06, 23.0MB/s]model.safetensors:  74%|███████▍  | 368M/498M [00:13<00:04, 26.4MB/s]model.safetensors:  77%|███████▋  | 384M/498M [00:13<00:03, 32.5MB/s]model.safetensors:  80%|████████  | 400M/498M [00:13<00:02, 38.3MB/s]model.safetensors:  84%|████████▎ | 416M/498M [00:14<00:01, 42.5MB/s]model.safetensors:  87%|████████▋ | 432M/498M [00:14<00:01, 40.2MB/s]model.safetensors:  89%|████████▉ | 445M/498M [00:14<00:01, 49.4MB/s]model.safetensors:  91%|█████████ | 453M/498M [00:14<00:00, 50.5MB/s]model.safetensors:  93%|█████████▎| 464M/498M [00:15<00:00, 49.6MB/s]model.safetensors:  96%|█████████▋| 480M/498M [00:15<00:00, 56.8MB/s]model.safetensors: 100%|█████████▉| 496M/498M [00:15<00:00, 59.2MB/s]model.safetensors: 100%|██████████| 498M/498M [00:15<00:00, 31.6MB/s]
