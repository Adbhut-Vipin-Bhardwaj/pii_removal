Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
                                                   [A{'eval_loss': 2.2839365005493164, 'eval_runtime': 48.7182, 'eval_samples_per_second': 615.786, 'eval_steps_per_second': 76.973, 'eval_num_tokens': 279116.0, 'eval_mean_token_accuracy': 0.6463963125387827, 'epoch': 0.04}
                                                   [A{'eval_loss': 2.1764256954193115, 'eval_runtime': 48.7487, 'eval_samples_per_second': 615.401, 'eval_steps_per_second': 76.925, 'eval_num_tokens': 557915.0, 'eval_mean_token_accuracy': 0.6593949148575465, 'epoch': 0.09}
                                                   [A{'eval_loss': 2.0812625885009766, 'eval_runtime': 48.7925, 'eval_samples_per_second': 614.849, 'eval_steps_per_second': 76.856, 'eval_num_tokens': 838165.0, 'eval_mean_token_accuracy': 0.6706397917350133, 'epoch': 0.13}
                                                   [A{'eval_loss': 2.0212879180908203, 'eval_runtime': 48.702, 'eval_samples_per_second': 615.991, 'eval_steps_per_second': 76.999, 'eval_num_tokens': 1118081.0, 'eval_mean_token_accuracy': 0.6773898871978123, 'epoch': 0.18}
                                                   [A{'eval_loss': 1.955325961112976, 'eval_runtime': 48.7317, 'eval_samples_per_second': 615.615, 'eval_steps_per_second': 76.952, 'eval_num_tokens': 1398519.0, 'eval_mean_token_accuracy': 0.6841648500919342, 'epoch': 0.22}
                                                   [A{'eval_loss': 1.9163569211959839, 'eval_runtime': 48.5454, 'eval_samples_per_second': 617.978, 'eval_steps_per_second': 77.247, 'eval_num_tokens': 1676496.0, 'eval_mean_token_accuracy': 0.6892072152058284, 'epoch': 0.27}
                                                   [A{'eval_loss': 1.8651155233383179, 'eval_runtime': 48.3351, 'eval_samples_per_second': 620.667, 'eval_steps_per_second': 77.583, 'eval_num_tokens': 1955133.0, 'eval_mean_token_accuracy': 0.6935583548784257, 'epoch': 0.31}
                                                   [A{'eval_loss': 1.8278639316558838, 'eval_runtime': 48.6002, 'eval_samples_per_second': 617.281, 'eval_steps_per_second': 77.16, 'eval_num_tokens': 2236732.0, 'eval_mean_token_accuracy': 0.6974666965325673, 'epoch': 0.35}
                                                   [A{'eval_loss': 1.794420838356018, 'eval_runtime': 48.4698, 'eval_samples_per_second': 618.942, 'eval_steps_per_second': 77.368, 'eval_num_tokens': 2513384.0, 'eval_mean_token_accuracy': 0.7022815903425217, 'epoch': 0.4}
                                                   [A{'eval_loss': 1.759670615196228, 'eval_runtime': 48.5797, 'eval_samples_per_second': 617.542, 'eval_steps_per_second': 77.193, 'eval_num_tokens': 2790289.0, 'eval_mean_token_accuracy': 0.7050293350537618, 'epoch': 0.44}
                                                   [A{'eval_loss': 1.7236385345458984, 'eval_runtime': 48.4494, 'eval_samples_per_second': 619.202, 'eval_steps_per_second': 77.4, 'eval_num_tokens': 3068708.0, 'eval_mean_token_accuracy': 0.7094802689790726, 'epoch': 0.49}
                                                   [A{'eval_loss': 1.6981971263885498, 'eval_runtime': 48.2507, 'eval_samples_per_second': 621.753, 'eval_steps_per_second': 77.719, 'eval_num_tokens': 3346171.0, 'eval_mean_token_accuracy': 0.7120769698619842, 'epoch': 0.53}
                                                   [A{'eval_loss': 1.6719483137130737, 'eval_runtime': 48.4569, 'eval_samples_per_second': 619.107, 'eval_steps_per_second': 77.388, 'eval_num_tokens': 3624935.0, 'eval_mean_token_accuracy': 0.7149305818637212, 'epoch': 0.57}
                                                   [A{'eval_loss': 1.6511470079421997, 'eval_runtime': 48.7339, 'eval_samples_per_second': 615.588, 'eval_steps_per_second': 76.949, 'eval_num_tokens': 3900788.0, 'eval_mean_token_accuracy': 0.7176393690347671, 'epoch': 0.62}
                                                   [A{'eval_loss': 1.6396503448486328, 'eval_runtime': 48.6791, 'eval_samples_per_second': 616.281, 'eval_steps_per_second': 77.035, 'eval_num_tokens': 4179807.0, 'eval_mean_token_accuracy': 0.7189666128238043, 'epoch': 0.66}
                                                   [AThere were missing keys in the checkpoint model loaded: ['lm_head.weight'].
                                                   {'train_runtime': 1135.7938, 'train_samples_per_second': 52.826, 'train_steps_per_second': 6.603, 'train_loss': 1.9251103678385417, 'num_tokens': 4179807.0, 'mean_token_accuracy': 0.6824629240125417, 'epoch': 0.66}
Time taken by training: 18.93 minutes
