Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Generating train split:   0%|          | 0/464150 [00:00<?, ? examples/s]Generating train split:  11%|█         | 50996/464150 [00:00<00:00, 465842.96 examples/s]Generating train split:  24%|██▍       | 111326/464150 [00:00<00:00, 502706.03 examples/s]Generating train split:  37%|███▋      | 171259/464150 [00:00<00:00, 510837.03 examples/s]Generating train split:  52%|█████▏    | 240076/464150 [00:00<00:00, 526669.76 examples/s]Generating train split:  65%|██████▍   | 300282/464150 [00:00<00:00, 522366.74 examples/s]Generating train split:  78%|███████▊  | 360314/464150 [00:00<00:00, 504053.42 examples/s]Generating train split:  93%|█████████▎| 429674/464150 [00:00<00:00, 527306.69 examples/s]Generating train split: 100%|██████████| 464150/464150 [00:00<00:00, 523262.81 examples/s]
Generating validation split:   0%|          | 0/116077 [00:00<?, ? examples/s]Generating validation split:  59%|█████▉    | 68491/116077 [00:00<00:00, 478845.85 examples/s]Generating validation split: 100%|██████████| 116077/116077 [00:00<00:00, 489977.50 examples/s]
Filter:   0%|          | 0/464150 [00:00<?, ? examples/s]Filter:   0%|          | 2000/464150 [00:00<00:26, 17321.46 examples/s]Filter:   1%|          | 4000/464150 [00:00<00:25, 18077.27 examples/s]Filter:   2%|▏         | 8000/464150 [00:00<00:22, 20119.05 examples/s]Filter:   2%|▏         | 10000/464150 [00:00<00:23, 19402.04 examples/s]Filter:   3%|▎         | 12000/464150 [00:00<00:24, 18677.82 examples/s]Filter:   3%|▎         | 14000/464150 [00:00<00:24, 18501.30 examples/s]Filter:   4%|▎         | 17000/464150 [00:00<00:25, 17297.87 examples/s]Filter:   4%|▍         | 20000/464150 [00:01<00:23, 18586.19 examples/s]Filter:   5%|▍         | 22000/464150 [00:01<00:23, 18664.79 examples/s]Filter:   5%|▌         | 24000/464150 [00:01<00:23, 18963.34 examples/s]Filter:   6%|▌         | 28000/464150 [00:01<00:21, 20043.75 examples/s]Filter:   7%|▋         | 31000/464150 [00:01<00:21, 20124.91 examples/s]Filter:   7%|▋         | 34000/464150 [00:01<00:21, 19744.67 examples/s]Filter:   8%|▊         | 38000/464150 [00:01<00:20, 20480.83 examples/s]Filter:   9%|▉         | 41000/464150 [00:02<00:21, 19862.52 examples/s]Filter:   9%|▉         | 43000/464150 [00:02<00:21, 19516.45 examples/s]Filter:  10%|▉         | 45000/464150 [00:02<00:21, 19334.65 examples/s]Filter:  10%|█         | 47000/464150 [00:02<00:21, 19356.07 examples/s]Filter:  11%|█         | 50000/464150 [00:02<00:21, 19447.75 examples/s]Filter:  11%|█         | 52000/464150 [00:02<00:21, 19087.97 examples/s]Filter:  12%|█▏        | 54000/464150 [00:02<00:21, 19036.51 examples/s]Filter:  12%|█▏        | 57000/464150 [00:02<00:20, 19510.92 examples/s]Filter:  13%|█▎        | 61000/464150 [00:03<00:19, 20764.29 examples/s]Filter:  14%|█▍        | 64000/464150 [00:03<00:19, 20180.34 examples/s]Filter:  15%|█▍        | 68000/464150 [00:03<00:19, 20837.29 examples/s]Filter:  15%|█▌        | 71000/464150 [00:03<00:22, 17812.89 examples/s]Filter:  16%|█▌        | 73000/464150 [00:03<00:21, 17921.76 examples/s]Filter:  16%|█▌        | 75000/464150 [00:03<00:21, 18160.01 examples/s]Filter:  17%|█▋        | 78000/464150 [00:04<00:20, 18986.76 examples/s]Filter:  18%|█▊        | 82000/464150 [00:04<00:19, 19922.75 examples/s]Filter:  18%|█▊        | 84000/464150 [00:04<00:19, 19634.79 examples/s]Filter:  19%|█▊        | 87000/464150 [00:04<00:18, 20074.24 examples/s]Filter:  19%|█▉        | 90000/464150 [00:04<00:18, 20063.36 examples/s]Filter:  20%|██        | 93000/464150 [00:04<00:18, 19687.99 examples/s]Filter:  21%|██        | 96000/464150 [00:04<00:18, 20099.74 examples/s]Filter:  21%|██▏       | 99000/464150 [00:05<00:18, 19733.51 examples/s]Filter:  22%|██▏       | 101000/464150 [00:05<00:18, 19451.29 examples/s]Filter:  22%|██▏       | 104000/464150 [00:05<00:18, 19607.49 examples/s]Filter:  23%|██▎       | 107000/464150 [00:05<00:17, 20206.76 examples/s]Filter:  24%|██▎       | 110000/464150 [00:05<00:17, 19786.61 examples/s]Filter:  25%|██▍       | 114000/464150 [00:05<00:16, 20605.25 examples/s]Filter:  25%|██▌       | 117000/464150 [00:06<00:18, 19281.55 examples/s]Filter:  26%|██▌       | 119000/464150 [00:06<00:19, 17329.19 examples/s]Filter:  26%|██▌       | 121000/464150 [00:06<00:20, 16582.80 examples/s]Filter:  27%|██▋       | 124000/464150 [00:06<00:19, 17381.41 examples/s]Filter:  28%|██▊       | 128000/464150 [00:06<00:17, 19010.10 examples/s]Filter:  28%|██▊       | 130000/464150 [00:06<00:17, 18844.33 examples/s]Filter:  28%|██▊       | 132000/464150 [00:06<00:17, 18951.67 examples/s]Filter:  29%|██▉       | 136000/464150 [00:07<00:16, 19830.84 examples/s]Filter:  30%|██▉       | 139000/464150 [00:07<00:16, 20114.57 examples/s]Filter:  30%|███       | 141000/464150 [00:07<00:16, 19596.31 examples/s]Filter:  31%|███       | 143000/464150 [00:07<00:16, 19493.90 examples/s]Filter:  32%|███▏      | 147000/464150 [00:07<00:15, 20298.95 examples/s]Filter:  32%|███▏      | 149000/464150 [00:07<00:15, 19742.22 examples/s]Filter:  33%|███▎      | 151000/464150 [00:07<00:16, 19544.53 examples/s]Filter:  33%|███▎      | 154000/464150 [00:07<00:15, 20108.98 examples/s]Filter:  34%|███▎      | 156000/464150 [00:08<00:15, 20050.29 examples/s]Filter:  34%|███▍      | 158000/464150 [00:08<00:15, 19445.53 examples/s]Filter:  34%|███▍      | 160000/464150 [00:08<00:15, 19191.34 examples/s]Filter:  35%|███▌      | 163000/464150 [00:08<00:15, 19475.40 examples/s]Filter:  36%|███▌      | 166000/464150 [00:08<00:14, 20058.15 examples/s]Filter:  36%|███▌      | 168000/464150 [00:08<00:15, 19736.35 examples/s]Filter:  37%|███▋      | 170000/464150 [00:08<00:15, 19221.96 examples/s]Filter:  37%|███▋      | 174000/464150 [00:08<00:14, 20165.44 examples/s]Filter:  38%|███▊      | 176000/464150 [00:09<00:14, 19654.56 examples/s]Filter:  38%|███▊      | 178000/464150 [00:09<00:14, 19539.59 examples/s]Filter:  39%|███▉      | 182000/464150 [00:09<00:13, 20166.80 examples/s]Filter:  40%|███▉      | 185000/464150 [00:09<00:13, 20375.88 examples/s]Filter:  41%|████      | 188000/464150 [00:09<00:14, 19543.91 examples/s]Filter:  41%|████      | 190000/464150 [00:09<00:14, 19275.87 examples/s]Filter:  41%|████▏     | 192000/464150 [00:09<00:14, 19349.31 examples/s]Filter:  42%|████▏     | 194000/464150 [00:10<00:15, 17078.63 examples/s]Filter:  43%|████▎     | 198000/464150 [00:10<00:13, 19019.25 examples/s]Filter:  43%|████▎     | 200000/464150 [00:10<00:14, 18848.14 examples/s]Filter:  44%|████▎     | 203000/464150 [00:10<00:13, 19112.25 examples/s]Filter:  45%|████▍     | 207000/464150 [00:10<00:13, 19534.72 examples/s]Filter:  45%|████▌     | 209000/464150 [00:10<00:13, 19293.88 examples/s]Filter:  46%|████▌     | 213000/464150 [00:10<00:12, 20150.59 examples/s]Filter:  46%|████▋     | 215000/464150 [00:11<00:12, 19587.82 examples/s]Filter:  47%|████▋     | 217000/464150 [00:11<00:12, 19281.03 examples/s]Filter:  47%|████▋     | 219000/464150 [00:11<00:12, 19240.35 examples/s]Filter:  48%|████▊     | 223000/464150 [00:11<00:11, 20249.32 examples/s]Filter:  48%|████▊     | 225000/464150 [00:11<00:12, 19743.09 examples/s]Filter:  49%|████▉     | 228000/464150 [00:11<00:11, 19813.49 examples/s]Filter:  50%|████▉     | 231000/464150 [00:11<00:11, 20420.07 examples/s]Filter:  50%|█████     | 234000/464150 [00:12<00:11, 19447.89 examples/s]Filter:  51%|█████     | 236000/464150 [00:12<00:11, 19224.03 examples/s]Filter:  51%|█████▏    | 238000/464150 [00:12<00:11, 19234.47 examples/s]Filter:  52%|█████▏    | 242000/464150 [00:12<00:11, 19947.36 examples/s]Filter:  53%|█████▎    | 245000/464150 [00:12<00:10, 20445.66 examples/s]Filter:  53%|█████▎    | 248000/464150 [00:12<00:10, 19864.70 examples/s]Filter:  54%|█████▍    | 251000/464150 [00:12<00:10, 20093.63 examples/s]Filter:  55%|█████▍    | 255000/464150 [00:13<00:10, 20753.86 examples/s]Filter:  56%|█████▌    | 258000/464150 [00:13<00:10, 19888.42 examples/s]Filter:  56%|█████▌    | 260000/464150 [00:13<00:10, 19657.79 examples/s]Filter:  57%|█████▋    | 264000/464150 [00:13<00:09, 20422.60 examples/s]Filter:  58%|█████▊    | 267000/464150 [00:13<00:09, 19728.73 examples/s]Filter:  58%|█████▊    | 270000/464150 [00:13<00:09, 19834.34 examples/s]Filter:  59%|█████▉    | 273000/464150 [00:13<00:09, 20103.26 examples/s]Filter:  59%|█████▉    | 276000/464150 [00:14<00:09, 19449.18 examples/s]Filter:  60%|█████▉    | 278000/464150 [00:14<00:09, 19113.67 examples/s]Filter:  61%|██████    | 282000/464150 [00:14<00:09, 20018.71 examples/s]Filter:  61%|██████    | 284000/464150 [00:14<00:09, 19569.48 examples/s]Filter:  62%|██████▏   | 286000/464150 [00:14<00:09, 19532.00 examples/s]Filter:  62%|██████▏   | 290000/464150 [00:14<00:08, 20191.33 examples/s]Filter:  63%|██████▎   | 292000/464150 [00:14<00:08, 19642.09 examples/s]Filter:  63%|██████▎   | 294000/464150 [00:15<00:08, 19244.52 examples/s]Filter:  64%|██████▍   | 296000/464150 [00:15<00:08, 19106.77 examples/s]Filter:  64%|██████▍   | 299000/464150 [00:15<00:08, 19515.02 examples/s]Filter:  65%|██████▌   | 303000/464150 [00:15<00:07, 20622.39 examples/s]Filter:  66%|██████▌   | 306000/464150 [00:15<00:07, 19844.03 examples/s]Filter:  66%|██████▋   | 308000/464150 [00:15<00:07, 19768.05 examples/s]Filter:  67%|██████▋   | 312000/464150 [00:15<00:07, 20441.73 examples/s]Filter:  68%|██████▊   | 315000/464150 [00:16<00:07, 20360.64 examples/s]Filter:  69%|██████▊   | 318000/464150 [00:16<00:07, 19774.55 examples/s]Filter:  69%|██████▉   | 321000/464150 [00:16<00:07, 19980.33 examples/s]Filter:  70%|██████▉   | 323000/464150 [00:16<00:07, 17871.71 examples/s]Filter:  70%|███████   | 325000/464150 [00:16<00:07, 17706.82 examples/s]Filter:  70%|███████   | 327000/464150 [00:16<00:07, 17865.94 examples/s]Filter:  71%|███████   | 329000/464150 [00:16<00:07, 18093.24 examples/s]Filter:  72%|███████▏  | 333000/464150 [00:17<00:06, 19446.13 examples/s]Filter:  72%|███████▏  | 335000/464150 [00:17<00:06, 19171.17 examples/s]Filter:  73%|███████▎  | 338000/464150 [00:17<00:06, 19502.78 examples/s]Filter:  73%|███████▎  | 341000/464150 [00:17<00:06, 19101.08 examples/s]Filter:  74%|███████▍  | 343000/464150 [00:17<00:06, 18029.07 examples/s]Filter:  74%|███████▍  | 345000/464150 [00:17<00:06, 18289.20 examples/s]Filter:  75%|███████▌  | 349000/464150 [00:17<00:05, 19721.78 examples/s]Filter:  76%|███████▌  | 351000/464150 [00:18<00:05, 19257.66 examples/s]Filter:  76%|███████▌  | 353000/464150 [00:18<00:05, 18847.56 examples/s]Filter:  76%|███████▋  | 355000/464150 [00:18<00:05, 18766.54 examples/s]Filter:  77%|███████▋  | 357000/464150 [00:18<00:05, 18918.72 examples/s]Filter:  78%|███████▊  | 361000/464150 [00:18<00:05, 19857.53 examples/s]Filter:  78%|███████▊  | 364000/464150 [00:18<00:04, 20379.51 examples/s]Filter:  79%|███████▉  | 367000/464150 [00:18<00:04, 19850.07 examples/s]Filter:  80%|███████▉  | 369000/464150 [00:18<00:04, 19660.85 examples/s]Filter:  80%|████████  | 372000/464150 [00:19<00:04, 19971.04 examples/s]Filter:  81%|████████  | 375000/464150 [00:19<00:04, 19864.30 examples/s]Filter:  81%|████████  | 377000/464150 [00:19<00:04, 19577.36 examples/s]Filter:  82%|████████▏ | 380000/464150 [00:19<00:04, 19824.47 examples/s]Filter:  83%|████████▎ | 383000/464150 [00:19<00:03, 20294.99 examples/s]Filter:  83%|████████▎ | 386000/464150 [00:19<00:03, 19663.45 examples/s]Filter:  84%|████████▍ | 389000/464150 [00:19<00:03, 19959.51 examples/s]Filter:  84%|████████▍ | 392000/464150 [00:20<00:03, 19957.64 examples/s]Filter:  85%|████████▍ | 394000/464150 [00:20<00:03, 19406.63 examples/s]Filter:  85%|████████▌ | 396000/464150 [00:20<00:03, 19285.11 examples/s]Filter:  86%|████████▌ | 400000/464150 [00:20<00:03, 20309.52 examples/s]Filter:  87%|████████▋ | 403000/464150 [00:20<00:03, 19847.04 examples/s]Filter:  87%|████████▋ | 406000/464150 [00:20<00:02, 19920.00 examples/s]Filter:  88%|████████▊ | 409000/464150 [00:21<00:02, 18732.31 examples/s]Filter:  89%|████████▊ | 411000/464150 [00:21<00:02, 18095.55 examples/s]Filter:  89%|████████▉ | 413000/464150 [00:21<00:02, 17615.50 examples/s]Filter:  89%|████████▉ | 415000/464150 [00:21<00:02, 17886.80 examples/s]Filter:  90%|█████████ | 418000/464150 [00:21<00:02, 18564.99 examples/s]Filter:  91%|█████████ | 422000/464150 [00:21<00:02, 19761.69 examples/s]Filter:  91%|█████████▏| 424000/464150 [00:21<00:02, 19505.70 examples/s]Filter:  92%|█████████▏| 427000/464150 [00:21<00:01, 19779.37 examples/s]Filter:  93%|█████████▎| 431000/464150 [00:22<00:01, 20780.15 examples/s]Filter:  94%|█████████▎| 434000/464150 [00:22<00:01, 19968.71 examples/s]Filter:  94%|█████████▍| 436000/464150 [00:22<00:01, 19726.93 examples/s]Filter:  95%|█████████▍| 440000/464150 [00:22<00:01, 20401.12 examples/s]Filter:  95%|█████████▌| 443000/464150 [00:22<00:01, 19674.98 examples/s]Filter:  96%|█████████▌| 446000/464150 [00:22<00:00, 19724.05 examples/s]Filter:  97%|█████████▋| 449000/464150 [00:23<00:00, 20192.91 examples/s]Filter:  97%|█████████▋| 452000/464150 [00:23<00:00, 19532.71 examples/s]Filter:  98%|█████████▊| 454000/464150 [00:23<00:00, 19470.26 examples/s]Filter:  99%|█████████▊| 458000/464150 [00:23<00:00, 19985.16 examples/s]Filter: 100%|█████████▉| 462000/464150 [00:23<00:00, 20471.94 examples/s]Filter: 100%|██████████| 464150/464150 [00:23<00:00, 18175.08 examples/s]Filter: 100%|██████████| 464150/464150 [00:23<00:00, 19457.27 examples/s]
Filter:   0%|          | 0/116077 [00:00<?, ? examples/s]Filter:   3%|▎         | 3000/116077 [00:00<00:05, 18915.24 examples/s]Filter:   5%|▌         | 6000/116077 [00:00<00:05, 19396.08 examples/s]Filter:   8%|▊         | 9000/116077 [00:00<00:05, 19727.07 examples/s]Filter:   9%|▉         | 11000/116077 [00:00<00:05, 19524.16 examples/s]Filter:  11%|█         | 13000/116077 [00:00<00:05, 19565.43 examples/s]Filter:  14%|█▍        | 16000/116077 [00:00<00:05, 19803.77 examples/s]Filter:  16%|█▌        | 18000/116077 [00:00<00:04, 19768.52 examples/s]Filter:  18%|█▊        | 21000/116077 [00:01<00:04, 19985.87 examples/s]Filter:  22%|██▏       | 25000/116077 [00:01<00:04, 19958.10 examples/s]Filter:  24%|██▍       | 28000/116077 [00:01<00:04, 19953.27 examples/s]Filter:  26%|██▌       | 30000/116077 [00:01<00:04, 19695.35 examples/s]Filter:  28%|██▊       | 33000/116077 [00:01<00:04, 19883.08 examples/s]Filter:  31%|███       | 36000/116077 [00:01<00:03, 20022.87 examples/s]Filter:  33%|███▎      | 38000/116077 [00:01<00:03, 19970.72 examples/s]Filter:  34%|███▍      | 40000/116077 [00:02<00:03, 19816.93 examples/s]Filter:  38%|███▊      | 44000/116077 [00:02<00:03, 19964.41 examples/s]Filter:  40%|████      | 47000/116077 [00:02<00:03, 20021.99 examples/s]Filter:  42%|████▏     | 49000/116077 [00:02<00:03, 19791.40 examples/s]Filter:  45%|████▍     | 52000/116077 [00:02<00:03, 19765.88 examples/s]Filter:  47%|████▋     | 54000/116077 [00:02<00:03, 19648.69 examples/s]Filter:  49%|████▉     | 57000/116077 [00:02<00:02, 19880.56 examples/s]Filter:  51%|█████     | 59000/116077 [00:02<00:02, 19641.13 examples/s]Filter:  53%|█████▎    | 62000/116077 [00:03<00:02, 19818.87 examples/s]Filter:  56%|█████▌    | 65000/116077 [00:03<00:02, 19896.97 examples/s]Filter:  58%|█████▊    | 67000/116077 [00:03<00:02, 19754.15 examples/s]Filter:  59%|█████▉    | 69000/116077 [00:03<00:02, 18731.44 examples/s]Filter:  63%|██████▎   | 73000/116077 [00:03<00:02, 19339.24 examples/s]Filter:  65%|██████▌   | 76000/116077 [00:03<00:02, 19650.51 examples/s]Filter:  68%|██████▊   | 79000/116077 [00:03<00:01, 19824.61 examples/s]Filter:  71%|███████   | 82000/116077 [00:04<00:01, 19787.57 examples/s]Filter:  74%|███████▍  | 86000/116077 [00:04<00:01, 19942.29 examples/s]Filter:  76%|███████▌  | 88000/116077 [00:04<00:01, 19932.51 examples/s]Filter:  78%|███████▊  | 91000/116077 [00:04<00:01, 20022.77 examples/s]Filter:  81%|████████  | 94000/116077 [00:04<00:01, 20040.15 examples/s]Filter:  84%|████████▍ | 98000/116077 [00:04<00:00, 20094.00 examples/s]Filter:  87%|████████▋ | 101000/116077 [00:05<00:00, 19899.70 examples/s]Filter:  89%|████████▊ | 103000/116077 [00:05<00:00, 19463.37 examples/s]Filter:  91%|█████████▏| 106000/116077 [00:05<00:00, 19405.48 examples/s]Filter:  94%|█████████▍| 109000/116077 [00:05<00:00, 19630.26 examples/s]Filter:  96%|█████████▋| 112000/116077 [00:05<00:00, 17684.58 examples/s]Filter:  99%|█████████▉| 115000/116077 [00:05<00:00, 18384.24 examples/s]Filter: 100%|██████████| 116077/116077 [00:05<00:00, 19600.04 examples/s]
Map:   0%|          | 0/90533 [00:00<?, ? examples/s]Map:   2%|▏         | 1525/90533 [00:00<00:05, 15160.59 examples/s]Map:   4%|▍         | 3787/90533 [00:00<00:05, 15068.28 examples/s]Map:   6%|▌         | 5313/90533 [00:00<00:05, 15139.94 examples/s]Map:   8%|▊         | 6866/90533 [00:00<00:05, 15276.96 examples/s]Map:  10%|█         | 9152/90533 [00:00<00:05, 15256.35 examples/s]Map:  12%|█▏        | 10706/90533 [00:00<00:05, 15334.66 examples/s]Map:  14%|█▍        | 13000/90533 [00:00<00:05, 15281.03 examples/s]Map:  17%|█▋        | 14974/90533 [00:01<00:05, 14523.57 examples/s]Map:  19%|█▊        | 16814/90533 [00:01<00:05, 13759.24 examples/s]Map:  21%|██        | 18898/90533 [00:01<00:05, 13799.49 examples/s]Map:  23%|██▎       | 20401/90533 [00:01<00:04, 14087.10 examples/s]Map:  24%|██▍       | 21938/90533 [00:01<00:04, 14408.21 examples/s]Map:  26%|██▌       | 23450/90533 [00:01<00:04, 14595.24 examples/s]Map:  28%|██▊       | 24988/90533 [00:01<00:04, 14808.00 examples/s]Map:  29%|██▉       | 26509/90533 [00:01<00:04, 14918.43 examples/s]Map:  31%|███       | 28025/90533 [00:01<00:04, 14982.79 examples/s]Map:  33%|███▎      | 29573/90533 [00:02<00:04, 15125.48 examples/s]Map:  35%|███▌      | 31866/90533 [00:02<00:03, 15183.82 examples/s]Map:  38%|███▊      | 34124/90533 [00:02<00:03, 15134.33 examples/s]Map:  39%|███▉      | 35661/90533 [00:02<00:03, 15192.08 examples/s]Map:  42%|████▏     | 37961/90533 [00:02<00:03, 15238.03 examples/s]Map:  44%|████▍     | 40229/90533 [00:02<00:03, 15194.25 examples/s]Map:  46%|████▌     | 41786/90533 [00:02<00:03, 15246.61 examples/s]Map:  49%|████▊     | 44037/90533 [00:02<00:03, 15161.37 examples/s]Map:  51%|█████     | 46290/90533 [00:03<00:02, 15112.07 examples/s]Map:  54%|█████▎    | 48544/90533 [00:03<00:02, 15081.93 examples/s]Map:  56%|█████▌    | 50832/90533 [00:03<00:02, 15131.55 examples/s]Map:  59%|█████▊    | 53090/90533 [00:03<00:02, 15104.63 examples/s]Map:  60%|██████    | 54624/90533 [00:03<00:02, 15154.82 examples/s]Map:  63%|██████▎   | 56900/90533 [00:03<00:02, 15157.56 examples/s]Map:  65%|██████▌   | 59152/90533 [00:03<00:02, 15108.35 examples/s]Map:  67%|██████▋   | 60684/90533 [00:04<00:01, 15155.60 examples/s]Map:  70%|██████▉   | 62964/90533 [00:04<00:01, 15167.40 examples/s]Map:  72%|███████▏  | 65229/90533 [00:04<00:01, 15142.01 examples/s]Map:  74%|███████▍  | 66782/90533 [00:04<00:01, 15192.78 examples/s]Map:  76%|███████▌  | 69023/90533 [00:04<00:01, 15105.48 examples/s]Map:  78%|███████▊  | 70560/90533 [00:04<00:01, 15166.03 examples/s]Map:  80%|████████  | 72833/90533 [00:04<00:01, 15157.22 examples/s]Map:  83%|████████▎ | 75086/90533 [00:05<00:01, 15108.61 examples/s]Map:  85%|████████▍ | 76621/90533 [00:05<00:00, 15163.15 examples/s]Map:  87%|████████▋ | 78894/90533 [00:05<00:00, 15155.15 examples/s]Map:  90%|████████▉ | 81140/90533 [00:05<00:00, 15092.70 examples/s]Map:  91%|█████████▏| 82671/90533 [00:05<00:00, 15141.25 examples/s]Map:  94%|█████████▍| 84940/90533 [00:05<00:00, 15131.05 examples/s]Map:  96%|█████████▋| 87193/90533 [00:05<00:00, 15092.49 examples/s]Map:  98%|█████████▊| 88721/90533 [00:05<00:00, 15132.69 examples/s]Map: 100%|██████████| 90533/90533 [00:06<00:00, 15081.69 examples/s]Map: 100%|██████████| 90533/90533 [00:06<00:00, 15011.84 examples/s]
Map:   0%|          | 0/30000 [00:00<?, ? examples/s]Map:   5%|▌         | 1526/30000 [00:00<00:01, 15169.49 examples/s]Map:  13%|█▎        | 3808/30000 [00:00<00:01, 15191.84 examples/s]Map:  20%|██        | 6083/30000 [00:00<00:01, 15172.18 examples/s]Map:  25%|██▌       | 7629/30000 [00:00<00:01, 15260.09 examples/s]Map:  33%|███▎      | 9918/30000 [00:00<00:01, 15255.44 examples/s]Map:  41%|████      | 12192/30000 [00:00<00:01, 15215.79 examples/s]Map:  46%|████▌     | 13721/30000 [00:00<00:01, 15233.55 examples/s]Map:  53%|█████▎    | 16000/30000 [00:01<00:00, 15162.24 examples/s]Map:  58%|█████▊    | 17540/30000 [00:01<00:00, 15219.62 examples/s]Map:  66%|██████▌   | 19841/30000 [00:01<00:00, 15259.35 examples/s]Map:  74%|███████▎  | 22124/30000 [00:01<00:00, 15240.45 examples/s]Map:  79%|███████▉  | 23666/30000 [00:01<00:00, 15279.36 examples/s]Map:  86%|████████▌ | 25838/30000 [00:01<00:00, 15003.85 examples/s]Map:  93%|█████████▎| 28034/30000 [00:01<00:00, 14881.31 examples/s]Map:  99%|█████████▊| 29578/30000 [00:01<00:00, 15011.87 examples/s]Map: 100%|██████████| 30000/30000 [00:01<00:00, 15127.95 examples/s]
Converting train dataset to ChatML:   0%|          | 0/90533 [00:00<?, ? examples/s]Converting train dataset to ChatML:   4%|▎         | 3279/90533 [00:00<00:02, 32679.78 examples/s]Converting train dataset to ChatML:   7%|▋         | 6589/90533 [00:00<00:02, 32923.88 examples/s]Converting train dataset to ChatML:  13%|█▎        | 11335/90533 [00:00<00:02, 26651.02 examples/s]Converting train dataset to ChatML:  16%|█▌        | 14679/90533 [00:00<00:02, 28583.78 examples/s]Converting train dataset to ChatML:  20%|█▉        | 17970/90533 [00:00<00:02, 29887.83 examples/s]Converting train dataset to ChatML:  23%|██▎       | 21202/90533 [00:00<00:02, 30620.94 examples/s]Converting train dataset to ChatML:  27%|██▋       | 24490/90533 [00:00<00:02, 31299.01 examples/s]Converting train dataset to ChatML:  31%|███       | 27772/90533 [00:00<00:01, 31753.93 examples/s]Converting train dataset to ChatML:  34%|███▍      | 31001/90533 [00:01<00:01, 31908.36 examples/s]Converting train dataset to ChatML:  38%|███▊      | 34290/90533 [00:01<00:01, 32200.76 examples/s]Converting train dataset to ChatML:  41%|████▏     | 37567/90533 [00:01<00:01, 32368.29 examples/s]Converting train dataset to ChatML:  45%|████▌     | 40850/90533 [00:01<00:01, 32505.32 examples/s]Converting train dataset to ChatML:  51%|█████     | 45750/90533 [00:01<00:01, 32564.61 examples/s]Converting train dataset to ChatML:  56%|█████▌    | 50611/90533 [00:01<00:01, 32387.44 examples/s]Converting train dataset to ChatML:  61%|██████    | 55104/90533 [00:01<00:01, 31560.10 examples/s]Converting train dataset to ChatML:  66%|██████▌   | 59865/90533 [00:01<00:00, 31616.69 examples/s]Converting train dataset to ChatML:  70%|██████▉   | 63066/90533 [00:02<00:00, 31707.45 examples/s]Converting train dataset to ChatML:  73%|███████▎  | 66353/90533 [00:02<00:00, 31998.33 examples/s]Converting train dataset to ChatML:  77%|███████▋  | 69677/90533 [00:02<00:00, 32243.87 examples/s]Converting train dataset to ChatML:  81%|████████  | 72965/90533 [00:02<00:00, 32415.40 examples/s]Converting train dataset to ChatML:  86%|████████▌ | 77894/90533 [00:02<00:00, 32576.63 examples/s]Converting train dataset to ChatML:  91%|█████████▏| 82812/90533 [00:02<00:00, 32645.35 examples/s]Converting train dataset to ChatML:  97%|█████████▋| 87731/90533 [00:02<00:00, 32691.78 examples/s]Converting train dataset to ChatML: 100%|██████████| 90533/90533 [00:02<00:00, 31772.48 examples/s]
Applying chat template to train dataset:   0%|          | 0/90533 [00:00<?, ? examples/s]Applying chat template to train dataset:   2%|▏         | 1490/90533 [00:00<00:06, 14839.27 examples/s]Applying chat template to train dataset:   3%|▎         | 3009/90533 [00:00<00:05, 15038.82 examples/s]Applying chat template to train dataset:   5%|▌         | 4547/90533 [00:00<00:05, 15189.88 examples/s]Applying chat template to train dataset:   7%|▋         | 6070/90533 [00:00<00:05, 15200.69 examples/s]Applying chat template to train dataset:   8%|▊         | 7612/90533 [00:00<00:05, 15276.48 examples/s]Applying chat template to train dataset:  11%|█         | 9892/90533 [00:00<00:05, 15238.94 examples/s]Applying chat template to train dataset:  13%|█▎        | 11425/90533 [00:00<00:05, 15263.58 examples/s]Applying chat template to train dataset:  14%|█▍        | 12968/90533 [00:00<00:05, 15307.06 examples/s]Applying chat template to train dataset:  17%|█▋        | 15262/90533 [00:01<00:04, 15297.30 examples/s]Applying chat template to train dataset:  19%|█▊        | 16805/90533 [00:01<00:04, 15329.26 examples/s]Applying chat template to train dataset:  20%|██        | 18339/90533 [00:01<00:04, 15329.01 examples/s]Applying chat template to train dataset:  22%|██▏       | 19877/90533 [00:01<00:04, 15341.74 examples/s]Applying chat template to train dataset:  24%|██▍       | 22166/90533 [00:01<00:04, 15307.50 examples/s]Applying chat template to train dataset:  27%|██▋       | 24151/90533 [00:01<00:04, 14575.18 examples/s]Applying chat template to train dataset:  29%|██▊       | 25973/90533 [00:01<00:04, 13756.65 examples/s]Applying chat template to train dataset:  30%|███       | 27365/90533 [00:01<00:04, 13793.13 examples/s]Applying chat template to train dataset:  32%|███▏      | 28763/90533 [00:01<00:04, 13836.12 examples/s]Applying chat template to train dataset:  33%|███▎      | 30289/90533 [00:02<00:04, 14213.85 examples/s]Applying chat template to train dataset:  35%|███▌      | 31822/90533 [00:02<00:04, 14518.66 examples/s]Applying chat template to train dataset:  37%|███▋      | 33351/90533 [00:02<00:03, 14734.63 examples/s]Applying chat template to train dataset:  39%|███▊      | 34886/90533 [00:02<00:03, 14908.28 examples/s]Applying chat template to train dataset:  40%|████      | 36410/90533 [00:02<00:03, 15000.66 examples/s]Applying chat template to train dataset:  42%|████▏     | 37940/90533 [00:02<00:03, 15086.79 examples/s]Applying chat template to train dataset:  44%|████▎     | 39470/90533 [00:02<00:03, 15145.85 examples/s]Applying chat template to train dataset:  45%|████▌     | 41000/90533 [00:02<00:03, 15173.88 examples/s]Applying chat template to train dataset:  47%|████▋     | 42525/90533 [00:02<00:03, 15193.59 examples/s]Applying chat template to train dataset:  49%|████▉     | 44811/90533 [00:03<00:03, 15210.27 examples/s]Applying chat template to train dataset:  52%|█████▏    | 47088/90533 [00:03<00:02, 15195.60 examples/s]Applying chat template to train dataset:  54%|█████▎    | 48615/90533 [00:03<00:02, 15212.64 examples/s]Applying chat template to train dataset:  56%|█████▌    | 50906/90533 [00:03<00:02, 15230.30 examples/s]Applying chat template to train dataset:  58%|█████▊    | 52430/90533 [00:03<00:02, 15229.70 examples/s]Applying chat template to train dataset:  60%|█████▉    | 53959/90533 [00:03<00:02, 15241.97 examples/s]Applying chat template to train dataset:  62%|██████▏   | 56245/90533 [00:03<00:02, 15238.17 examples/s]Applying chat template to train dataset:  64%|██████▍   | 57776/90533 [00:03<00:02, 15253.31 examples/s]Applying chat template to train dataset:  66%|██████▌   | 59302/90533 [00:03<00:02, 15252.49 examples/s]Applying chat template to train dataset:  67%|██████▋   | 60836/90533 [00:04<00:01, 15273.79 examples/s]Applying chat template to train dataset:  70%|██████▉   | 63125/90533 [00:04<00:01, 15262.24 examples/s]Applying chat template to train dataset:  71%|███████▏  | 64658/90533 [00:04<00:01, 15278.36 examples/s]Applying chat template to train dataset:  74%|███████▍  | 66933/90533 [00:04<00:01, 15237.22 examples/s]Applying chat template to train dataset:  76%|███████▋  | 69215/90533 [00:04<00:01, 15224.27 examples/s]Applying chat template to train dataset:  78%|███████▊  | 70739/90533 [00:04<00:01, 15226.92 examples/s]Applying chat template to train dataset:  81%|████████  | 73007/90533 [00:04<00:01, 15186.91 examples/s]Applying chat template to train dataset:  83%|████████▎ | 75281/90533 [00:05<00:01, 15175.53 examples/s]Applying chat template to train dataset:  85%|████████▍ | 76801/90533 [00:05<00:00, 15178.12 examples/s]Applying chat template to train dataset:  87%|████████▋ | 79069/90533 [00:05<00:00, 15155.87 examples/s]Applying chat template to train dataset:  89%|████████▉ | 80589/90533 [00:05<00:00, 15164.36 examples/s]Applying chat template to train dataset:  92%|█████████▏| 82874/90533 [00:05<00:00, 15185.61 examples/s]Applying chat template to train dataset:  94%|█████████▍| 85142/90533 [00:05<00:00, 15159.99 examples/s]Applying chat template to train dataset:  97%|█████████▋| 87412/90533 [00:05<00:00, 15146.16 examples/s]Applying chat template to train dataset:  98%|█████████▊| 88929/90533 [00:05<00:00, 15148.92 examples/s]Applying chat template to train dataset: 100%|██████████| 90533/90533 [00:06<00:00, 15131.79 examples/s]Applying chat template to train dataset: 100%|██████████| 90533/90533 [00:06<00:00, 15057.47 examples/s]
Tokenizing train dataset:   0%|          | 0/90533 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 639/90533 [00:00<00:14, 6357.12 examples/s]Tokenizing train dataset:   2%|▏         | 1573/90533 [00:00<00:14, 6260.90 examples/s]Tokenizing train dataset:   3%|▎         | 2495/90533 [00:00<00:14, 6201.90 examples/s]Tokenizing train dataset:   4%|▍         | 3418/90533 [00:00<00:14, 6177.11 examples/s]Tokenizing train dataset:   5%|▍         | 4348/90533 [00:00<00:13, 6182.32 examples/s]Tokenizing train dataset:   6%|▌         | 5000/90533 [00:00<00:13, 6154.06 examples/s]Tokenizing train dataset:   6%|▌         | 5652/90533 [00:00<00:13, 6248.08 examples/s]Tokenizing train dataset:   7%|▋         | 6571/90533 [00:01<00:13, 6197.41 examples/s]Tokenizing train dataset:   8%|▊         | 7496/90533 [00:01<00:13, 6182.42 examples/s]Tokenizing train dataset:   9%|▉         | 8419/90533 [00:01<00:13, 6169.63 examples/s]Tokenizing train dataset:  10%|█         | 9355/90533 [00:01<00:13, 6189.37 examples/s]Tokenizing train dataset:  11%|█         | 10000/90533 [00:01<00:13, 6150.42 examples/s]Tokenizing train dataset:  12%|█▏        | 10659/90533 [00:01<00:12, 6256.26 examples/s]Tokenizing train dataset:  13%|█▎        | 11594/90533 [00:01<00:12, 6244.58 examples/s]Tokenizing train dataset:  14%|█▍        | 12527/90533 [00:02<00:12, 6233.99 examples/s]Tokenizing train dataset:  15%|█▍        | 13469/90533 [00:02<00:12, 6245.69 examples/s]Tokenizing train dataset:  16%|█▌        | 14409/90533 [00:02<00:12, 6248.79 examples/s]Tokenizing train dataset:  17%|█▋        | 15340/90533 [00:02<00:12, 6232.67 examples/s]Tokenizing train dataset:  18%|█▊        | 16000/90533 [00:02<00:12, 6209.67 examples/s]Tokenizing train dataset:  18%|█▊        | 16667/90533 [00:02<00:11, 6318.37 examples/s]Tokenizing train dataset:  19%|█▉        | 17328/90533 [00:02<00:11, 6242.35 examples/s]Tokenizing train dataset:  20%|█▉        | 17993/90533 [00:02<00:11, 6345.36 examples/s]Tokenizing train dataset:  21%|██        | 18930/90533 [00:03<00:11, 6306.69 examples/s]Tokenizing train dataset:  22%|██▏       | 19869/90533 [00:03<00:11, 6286.43 examples/s]Tokenizing train dataset:  23%|██▎       | 20810/90533 [00:03<00:11, 6280.36 examples/s]Tokenizing train dataset:  24%|██▍       | 21742/90533 [00:03<00:10, 6254.90 examples/s]Tokenizing train dataset:  25%|██▌       | 22681/90533 [00:03<00:10, 6252.75 examples/s]Tokenizing train dataset:  26%|██▌       | 23327/90533 [00:03<00:10, 6214.23 examples/s]Tokenizing train dataset:  27%|██▋       | 23995/90533 [00:03<00:10, 6326.82 examples/s]Tokenizing train dataset:  28%|██▊       | 24936/90533 [00:03<00:10, 6306.12 examples/s]Tokenizing train dataset:  29%|██▊       | 25862/90533 [00:04<00:10, 6261.04 examples/s]Tokenizing train dataset:  30%|██▉       | 26794/90533 [00:04<00:10, 6244.07 examples/s]Tokenizing train dataset:  31%|███       | 27728/90533 [00:04<00:10, 6236.00 examples/s]Tokenizing train dataset:  32%|███▏      | 28675/90533 [00:04<00:09, 6255.44 examples/s]Tokenizing train dataset:  32%|███▏      | 29330/90533 [00:04<00:09, 6223.95 examples/s]Tokenizing train dataset:  33%|███▎      | 29985/90533 [00:04<00:09, 6301.50 examples/s]Tokenizing train dataset:  34%|███▍      | 30916/90533 [00:04<00:09, 6266.35 examples/s]Tokenizing train dataset:  35%|███▌      | 31845/90533 [00:05<00:09, 6238.30 examples/s]Tokenizing train dataset:  36%|███▌      | 32774/90533 [00:05<00:09, 6220.93 examples/s]Tokenizing train dataset:  37%|███▋      | 33653/90533 [00:05<00:09, 6103.54 examples/s]Tokenizing train dataset:  38%|███▊      | 34580/90533 [00:05<00:09, 6126.56 examples/s]Tokenizing train dataset:  39%|███▉      | 35507/90533 [00:05<00:08, 6140.35 examples/s]Tokenizing train dataset:  40%|████      | 36448/90533 [00:05<00:08, 6176.79 examples/s]Tokenizing train dataset:  41%|████▏     | 37388/90533 [00:06<00:08, 6202.09 examples/s]Tokenizing train dataset:  42%|████▏     | 38234/90533 [00:06<00:08, 6029.01 examples/s]Tokenizing train dataset:  43%|████▎     | 38903/90533 [00:06<00:08, 6173.69 examples/s]Tokenizing train dataset:  44%|████▍     | 39834/90533 [00:06<00:08, 6181.10 examples/s]Tokenizing train dataset:  45%|████▌     | 40782/90533 [00:06<00:07, 6222.94 examples/s]Tokenizing train dataset:  46%|████▌     | 41731/90533 [00:06<00:07, 6251.36 examples/s]Tokenizing train dataset:  47%|████▋     | 42686/90533 [00:06<00:07, 6281.87 examples/s]Tokenizing train dataset:  48%|████▊     | 43335/90533 [00:06<00:07, 6247.57 examples/s]Tokenizing train dataset:  49%|████▊     | 44000/90533 [00:07<00:07, 6234.76 examples/s]Tokenizing train dataset:  49%|████▉     | 44670/90533 [00:07<00:07, 6350.83 examples/s]Tokenizing train dataset:  50%|█████     | 45320/90533 [00:07<00:07, 6230.19 examples/s]Tokenizing train dataset:  51%|█████     | 46189/90533 [00:07<00:07, 6071.70 examples/s]Tokenizing train dataset:  52%|█████▏    | 46829/90533 [00:07<00:07, 6152.95 examples/s]Tokenizing train dataset:  53%|█████▎    | 47764/90533 [00:07<00:06, 6177.87 examples/s]Tokenizing train dataset:  54%|█████▍    | 48720/90533 [00:07<00:06, 6239.25 examples/s]Tokenizing train dataset:  55%|█████▍    | 49677/90533 [00:07<00:06, 6282.02 examples/s]Tokenizing train dataset:  56%|█████▌    | 50334/90533 [00:08<00:06, 6250.80 examples/s]Tokenizing train dataset:  56%|█████▋    | 50998/90533 [00:08<00:06, 6347.29 examples/s]Tokenizing train dataset:  57%|█████▋    | 51933/90533 [00:08<00:06, 6306.19 examples/s]Tokenizing train dataset:  58%|█████▊    | 52877/90533 [00:08<00:05, 6300.17 examples/s]Tokenizing train dataset:  59%|█████▉    | 53814/90533 [00:08<00:05, 6277.86 examples/s]Tokenizing train dataset:  60%|██████    | 54753/90533 [00:08<00:05, 6269.36 examples/s]Tokenizing train dataset:  62%|██████▏   | 55678/90533 [00:08<00:05, 6232.58 examples/s]Tokenizing train dataset:  62%|██████▏   | 56332/90533 [00:09<00:05, 6202.12 examples/s]Tokenizing train dataset:  63%|██████▎   | 56995/90533 [00:09<00:05, 6302.02 examples/s]Tokenizing train dataset:  64%|██████▍   | 57939/90533 [00:09<00:05, 6294.95 examples/s]Tokenizing train dataset:  65%|██████▌   | 58885/90533 [00:09<00:05, 6294.38 examples/s]Tokenizing train dataset:  66%|██████▌   | 59794/90533 [00:09<00:04, 6214.44 examples/s]Tokenizing train dataset:  67%|██████▋   | 60724/90533 [00:09<00:04, 6209.30 examples/s]Tokenizing train dataset:  68%|██████▊   | 61663/90533 [00:09<00:04, 6219.62 examples/s]Tokenizing train dataset:  69%|██████▉   | 62449/90533 [00:10<00:04, 5916.00 examples/s]Tokenizing train dataset:  70%|██████▉   | 63327/90533 [00:10<00:04, 5795.53 examples/s]Tokenizing train dataset:  71%|███████   | 63913/90533 [00:10<00:04, 5806.46 examples/s]Tokenizing train dataset:  72%|███████▏  | 64811/90533 [00:10<00:04, 5861.90 examples/s]Tokenizing train dataset:  73%|███████▎  | 65722/90533 [00:10<00:04, 5927.05 examples/s]Tokenizing train dataset:  73%|███████▎  | 66324/90533 [00:10<00:04, 5921.05 examples/s]Tokenizing train dataset:  74%|███████▍  | 66984/90533 [00:10<00:03, 6086.69 examples/s]Tokenizing train dataset:  75%|███████▌  | 67911/90533 [00:10<00:03, 6117.83 examples/s]Tokenizing train dataset:  76%|███████▌  | 68818/90533 [00:11<00:03, 6090.74 examples/s]Tokenizing train dataset:  77%|███████▋  | 69743/90533 [00:11<00:03, 6112.13 examples/s]Tokenizing train dataset:  78%|███████▊  | 70670/90533 [00:11<00:03, 6130.46 examples/s]Tokenizing train dataset:  79%|███████▉  | 71324/90533 [00:11<00:03, 6098.23 examples/s]Tokenizing train dataset:  80%|███████▉  | 71985/90533 [00:11<00:02, 6221.05 examples/s]Tokenizing train dataset:  81%|████████  | 72902/90533 [00:11<00:02, 6182.27 examples/s]Tokenizing train dataset:  82%|████████▏ | 73833/90533 [00:11<00:02, 6186.91 examples/s]Tokenizing train dataset:  83%|████████▎ | 74738/90533 [00:12<00:02, 6134.98 examples/s]Tokenizing train dataset:  84%|████████▎ | 75646/90533 [00:12<00:02, 6104.98 examples/s]Tokenizing train dataset:  85%|████████▍ | 76560/90533 [00:12<00:02, 6099.83 examples/s]Tokenizing train dataset:  86%|████████▌ | 77486/90533 [00:12<00:02, 6118.76 examples/s]Tokenizing train dataset:  87%|████████▋ | 78408/90533 [00:12<00:01, 6124.93 examples/s]Tokenizing train dataset:  88%|████████▊ | 79334/90533 [00:12<00:01, 6137.47 examples/s]Tokenizing train dataset:  88%|████████▊ | 79996/90533 [00:12<00:01, 6243.49 examples/s]Tokenizing train dataset:  89%|████████▉ | 80917/90533 [00:13<00:01, 6205.82 examples/s]Tokenizing train dataset:  90%|█████████ | 81851/90533 [00:13<00:01, 6210.19 examples/s]Tokenizing train dataset:  91%|█████████▏| 82789/90533 [00:13<00:01, 6218.57 examples/s]Tokenizing train dataset:  92%|█████████▏| 83729/90533 [00:13<00:01, 6228.45 examples/s]Tokenizing train dataset:  94%|█████████▎| 84662/90533 [00:13<00:00, 6223.96 examples/s]Tokenizing train dataset:  95%|█████████▍| 85589/90533 [00:13<00:00, 6207.31 examples/s]Tokenizing train dataset:  96%|█████████▌| 86519/90533 [00:13<00:00, 6202.77 examples/s]Tokenizing train dataset:  97%|█████████▋| 87439/90533 [00:14<00:00, 6180.30 examples/s]Tokenizing train dataset:  98%|█████████▊| 88374/90533 [00:14<00:00, 6192.62 examples/s]Tokenizing train dataset:  98%|█████████▊| 89000/90533 [00:14<00:00, 6150.32 examples/s]Tokenizing train dataset:  99%|█████████▉| 89778/90533 [00:14<00:00, 5485.38 examples/s]Tokenizing train dataset: 100%|█████████▉| 90375/90533 [00:14<00:00, 5592.73 examples/s]Tokenizing train dataset: 100%|██████████| 90533/90533 [00:14<00:00, 6164.49 examples/s]
Truncating train dataset:   0%|          | 0/90533 [00:00<?, ? examples/s]Truncating train dataset: 100%|██████████| 90533/90533 [00:00<00:00, 3286619.96 examples/s]
Converting eval dataset to ChatML:   0%|          | 0/30000 [00:00<?, ? examples/s]Converting eval dataset to ChatML:  11%|█         | 3317/30000 [00:00<00:00, 33073.51 examples/s]Converting eval dataset to ChatML:  22%|██▏       | 6704/30000 [00:00<00:00, 33298.48 examples/s]Converting eval dataset to ChatML:  39%|███▉      | 11708/30000 [00:00<00:00, 33318.61 examples/s]Converting eval dataset to ChatML:  56%|█████▌    | 16717/30000 [00:00<00:00, 33347.93 examples/s]Converting eval dataset to ChatML:  72%|███████▏  | 21713/30000 [00:00<00:00, 33327.80 examples/s]Converting eval dataset to ChatML:  89%|████████▉ | 26720/30000 [00:00<00:00, 33341.81 examples/s]Converting eval dataset to ChatML: 100%|██████████| 30000/30000 [00:00<00:00, 33228.90 examples/s]
Applying chat template to eval dataset:   0%|          | 0/30000 [00:00<?, ? examples/s]Applying chat template to eval dataset:   5%|▌         | 1520/30000 [00:00<00:01, 15133.19 examples/s]Applying chat template to eval dataset:  10%|█         | 3038/30000 [00:00<00:01, 15154.34 examples/s]Applying chat template to eval dataset:  15%|█▌        | 4571/30000 [00:00<00:01, 15231.02 examples/s]Applying chat template to eval dataset:  23%|██▎       | 6861/30000 [00:00<00:01, 15241.55 examples/s]Applying chat template to eval dataset:  28%|██▊       | 8389/30000 [00:00<00:01, 15250.29 examples/s]Applying chat template to eval dataset:  33%|███▎      | 9921/30000 [00:00<00:01, 15270.31 examples/s]Applying chat template to eval dataset:  41%|████      | 12206/30000 [00:00<00:01, 15254.26 examples/s]Applying chat template to eval dataset:  46%|████▌     | 13741/30000 [00:00<00:01, 15280.66 examples/s]Applying chat template to eval dataset:  51%|█████     | 15270/30000 [00:01<00:00, 15279.86 examples/s]Applying chat template to eval dataset:  56%|█████▌    | 16805/30000 [00:01<00:00, 15294.75 examples/s]Applying chat template to eval dataset:  64%|██████▎   | 19092/30000 [00:01<00:00, 15271.22 examples/s]Applying chat template to eval dataset:  69%|██████▉   | 20625/30000 [00:01<00:00, 15284.45 examples/s]Applying chat template to eval dataset:  76%|███████▋  | 22924/30000 [00:01<00:00, 15295.55 examples/s]Applying chat template to eval dataset:  84%|████████▍ | 25203/30000 [00:01<00:00, 15256.67 examples/s]Applying chat template to eval dataset:  89%|████████▉ | 26735/30000 [00:01<00:00, 15268.88 examples/s]Applying chat template to eval dataset:  97%|█████████▋| 29024/30000 [00:01<00:00, 15262.12 examples/s]Applying chat template to eval dataset: 100%|██████████| 30000/30000 [00:01<00:00, 15257.06 examples/s]
Tokenizing eval dataset:   0%|          | 0/30000 [00:00<?, ? examples/s]Tokenizing eval dataset:   2%|▏         | 670/30000 [00:00<00:04, 6672.41 examples/s]Tokenizing eval dataset:   6%|▌         | 1669/30000 [00:00<00:04, 6393.68 examples/s]Tokenizing eval dataset:   9%|▊         | 2598/30000 [00:00<00:04, 6292.76 examples/s]Tokenizing eval dataset:  12%|█▏        | 3526/30000 [00:00<00:04, 6248.21 examples/s]Tokenizing eval dataset:  15%|█▍        | 4461/30000 [00:00<00:04, 6239.30 examples/s]Tokenizing eval dataset:  18%|█▊        | 5396/30000 [00:00<00:03, 6231.98 examples/s]Tokenizing eval dataset:  21%|██        | 6336/30000 [00:01<00:03, 6239.97 examples/s]Tokenizing eval dataset:  23%|██▎       | 6994/30000 [00:01<00:03, 6319.32 examples/s]Tokenizing eval dataset:  26%|██▋       | 7933/30000 [00:01<00:03, 6296.45 examples/s]Tokenizing eval dataset:  29%|██▉       | 8821/30000 [00:01<00:03, 6171.22 examples/s]Tokenizing eval dataset:  32%|███▏      | 9679/30000 [00:01<00:03, 6024.80 examples/s]Tokenizing eval dataset:  34%|███▍      | 10329/30000 [00:01<00:03, 6036.72 examples/s]Tokenizing eval dataset:  37%|███▋      | 10999/30000 [00:01<00:03, 6197.55 examples/s]Tokenizing eval dataset:  40%|███▉      | 11941/30000 [00:01<00:02, 6224.52 examples/s]Tokenizing eval dataset:  43%|████▎     | 12880/30000 [00:02<00:02, 6233.21 examples/s]Tokenizing eval dataset:  46%|████▌     | 13824/30000 [00:02<00:02, 6247.03 examples/s]Tokenizing eval dataset:  49%|████▉     | 14769/30000 [00:02<00:02, 6258.60 examples/s]Tokenizing eval dataset:  52%|█████▏    | 15720/30000 [00:02<00:02, 6282.92 examples/s]Tokenizing eval dataset:  56%|█████▌    | 16664/30000 [00:02<00:02, 6274.04 examples/s]Tokenizing eval dataset:  58%|█████▊    | 17335/30000 [00:02<00:02, 6242.05 examples/s]Tokenizing eval dataset:  60%|██████    | 18000/30000 [00:02<00:01, 6222.48 examples/s]Tokenizing eval dataset:  63%|██████▎   | 18920/30000 [00:03<00:01, 6189.24 examples/s]Tokenizing eval dataset:  66%|██████▌   | 19798/30000 [00:03<00:01, 6077.92 examples/s]Tokenizing eval dataset:  69%|██████▉   | 20733/30000 [00:03<00:01, 6123.73 examples/s]Tokenizing eval dataset:  72%|███████▏  | 21680/30000 [00:03<00:01, 6179.02 examples/s]Tokenizing eval dataset:  74%|███████▍  | 22330/30000 [00:03<00:01, 6176.68 examples/s]Tokenizing eval dataset:  77%|███████▋  | 23000/30000 [00:03<00:01, 6183.64 examples/s]Tokenizing eval dataset:  79%|███████▉  | 23678/30000 [00:03<00:00, 6333.93 examples/s]Tokenizing eval dataset:  81%|████████  | 24339/30000 [00:03<00:00, 6300.79 examples/s]Tokenizing eval dataset:  83%|████████▎ | 25000/30000 [00:04<00:00, 6258.20 examples/s]Tokenizing eval dataset:  86%|████████▌ | 25667/30000 [00:04<00:00, 6369.03 examples/s]Tokenizing eval dataset:  88%|████████▊ | 26336/30000 [00:04<00:00, 6309.86 examples/s]Tokenizing eval dataset:  90%|█████████ | 27000/30000 [00:04<00:00, 6274.38 examples/s]Tokenizing eval dataset:  92%|█████████▏| 27673/30000 [00:04<00:00, 6400.55 examples/s]Tokenizing eval dataset:  94%|█████████▍| 28336/30000 [00:04<00:00, 6311.56 examples/s]Tokenizing eval dataset:  97%|█████████▋| 29000/30000 [00:04<00:00, 6279.56 examples/s]Tokenizing eval dataset:  99%|█████████▉| 29675/30000 [00:04<00:00, 6411.69 examples/s]Tokenizing eval dataset: 100%|██████████| 30000/30000 [00:04<00:00, 6240.93 examples/s]
Truncating eval dataset:   0%|          | 0/30000 [00:00<?, ? examples/s]Truncating eval dataset: 100%|██████████| 30000/30000 [00:00<00:00, 2965010.60 examples/s]
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.
{'loss': 2.4003, 'grad_norm': 2.144688844680786, 'learning_rate': 0.0019556444444444447, 'epoch': 0.04418132013784572}
{'eval_loss': 1.2412724494934082, 'eval_runtime': 49.8338, 'eval_samples_per_second': 602.0, 'eval_steps_per_second': 75.25, 'eval_num_tokens': 279401.0, 'eval_mean_token_accuracy': 0.7702266233364741, 'epoch': 0.04418132013784572}
{'loss': 1.1116, 'grad_norm': 2.15574312210083, 'learning_rate': 0.0019112, 'epoch': 0.08836264027569143}
{'eval_loss': 0.6687017679214478, 'eval_runtime': 49.8713, 'eval_samples_per_second': 601.548, 'eval_steps_per_second': 75.194, 'eval_num_tokens': 559054.0, 'eval_mean_token_accuracy': 0.877110445412, 'epoch': 0.08836264027569143}
{'loss': 0.8767, 'grad_norm': 2.5879340171813965, 'learning_rate': 0.0018667555555555554, 'epoch': 0.13254396041353717}
{'eval_loss': 0.6249610781669617, 'eval_runtime': 49.8718, 'eval_samples_per_second': 601.542, 'eval_steps_per_second': 75.193, 'eval_num_tokens': 836233.0, 'eval_mean_token_accuracy': 0.8834149134000142, 'epoch': 0.13254396041353717}
{'loss': 0.7575, 'grad_norm': 2.3585565090179443, 'learning_rate': 0.0018223111111111113, 'epoch': 0.17672528055138287}
{'eval_loss': 0.533988893032074, 'eval_runtime': 49.8129, 'eval_samples_per_second': 602.254, 'eval_steps_per_second': 75.282, 'eval_num_tokens': 1115928.0, 'eval_mean_token_accuracy': 0.8992420997619629, 'epoch': 0.17672528055138287}
{'loss': 0.7205, 'grad_norm': 2.6742146015167236, 'learning_rate': 0.0017778666666666667, 'epoch': 0.2209066006892286}
{'eval_loss': 0.5646234154701233, 'eval_runtime': 49.8196, 'eval_samples_per_second': 602.172, 'eval_steps_per_second': 75.272, 'eval_num_tokens': 1397102.0, 'eval_mean_token_accuracy': 0.896199365846316, 'epoch': 0.2209066006892286}
{'loss': 0.6736, 'grad_norm': 3.858184576034546, 'learning_rate': 0.0017334222222222223, 'epoch': 0.26508792082707433}
{'eval_loss': 0.4945622980594635, 'eval_runtime': 49.7137, 'eval_samples_per_second': 603.456, 'eval_steps_per_second': 75.432, 'eval_num_tokens': 1673146.0, 'eval_mean_token_accuracy': 0.9052016965707144, 'epoch': 0.26508792082707433}
{'loss': 0.6453, 'grad_norm': 2.33901309967041, 'learning_rate': 0.0016889777777777777, 'epoch': 0.30926924096492003}
{'eval_loss': 0.4604986906051636, 'eval_runtime': 49.9421, 'eval_samples_per_second': 600.696, 'eval_steps_per_second': 75.087, 'eval_num_tokens': 1950691.0, 'eval_mean_token_accuracy': 0.9104453540802002, 'epoch': 0.30926924096492003}
{'loss': 0.6108, 'grad_norm': 4.166787147521973, 'learning_rate': 0.0016445333333333335, 'epoch': 0.35345056110276574}
{'eval_loss': 0.44625234603881836, 'eval_runtime': 49.7131, 'eval_samples_per_second': 603.463, 'eval_steps_per_second': 75.433, 'eval_num_tokens': 2226445.0, 'eval_mean_token_accuracy': 0.913361565987269, 'epoch': 0.35345056110276574}
{'loss': 0.6334, 'grad_norm': 1.86802339553833, 'learning_rate': 0.0016000888888888889, 'epoch': 0.3976318812406115}
{'eval_loss': 0.4633747339248657, 'eval_runtime': 49.8947, 'eval_samples_per_second': 601.266, 'eval_steps_per_second': 75.158, 'eval_num_tokens': 2504946.0, 'eval_mean_token_accuracy': 0.911244730703036, 'epoch': 0.3976318812406115}
{'loss': 0.6403, 'grad_norm': 1.3892247676849365, 'learning_rate': 0.0015556444444444445, 'epoch': 0.4418132013784572}
{'eval_loss': 0.4434927701950073, 'eval_runtime': 49.799, 'eval_samples_per_second': 602.422, 'eval_steps_per_second': 75.303, 'eval_num_tokens': 2783900.0, 'eval_mean_token_accuracy': 0.9125415320316951, 'epoch': 0.4418132013784572}
{'loss': 0.6126, 'grad_norm': 5.607832908630371, 'learning_rate': 0.0015112, 'epoch': 0.4859945215163029}
{'eval_loss': 0.47943779826164246, 'eval_runtime': 50.0006, 'eval_samples_per_second': 599.992, 'eval_steps_per_second': 74.999, 'eval_num_tokens': 3060330.0, 'eval_mean_token_accuracy': 0.9068788750569026, 'epoch': 0.4859945215163029}
{'loss': 0.6932, 'grad_norm': 17.38651466369629, 'learning_rate': 0.0014667555555555557, 'epoch': 0.5301758416541487}
{'eval_loss': 0.4838102161884308, 'eval_runtime': 49.7797, 'eval_samples_per_second': 602.656, 'eval_steps_per_second': 75.332, 'eval_num_tokens': 3340419.0, 'eval_mean_token_accuracy': 0.9048631417115529, 'epoch': 0.5301758416541487}
{'loss': 0.6753, 'grad_norm': 4.359596252441406, 'learning_rate': 0.001422311111111111, 'epoch': 0.5743571617919944}
{'eval_loss': 0.5090252161026001, 'eval_runtime': 49.6669, 'eval_samples_per_second': 604.025, 'eval_steps_per_second': 75.503, 'eval_num_tokens': 3619423.0, 'eval_mean_token_accuracy': 0.8996197469552358, 'epoch': 0.5743571617919944}
{'loss': 0.7426, 'grad_norm': 6.27296781539917, 'learning_rate': 0.0013778666666666667, 'epoch': 0.6185384819298401}
{'eval_loss': 0.49736207723617554, 'eval_runtime': 49.8978, 'eval_samples_per_second': 601.229, 'eval_steps_per_second': 75.154, 'eval_num_tokens': 3898682.0, 'eval_mean_token_accuracy': 0.9004452383995056, 'epoch': 0.6185384819298401}
{'loss': 0.6802, 'grad_norm': 7.32517147064209, 'learning_rate': 0.0013334222222222223, 'epoch': 0.6627198020676858}
{'eval_loss': 0.5058058500289917, 'eval_runtime': 49.5993, 'eval_samples_per_second': 604.847, 'eval_steps_per_second': 75.606, 'eval_num_tokens': 4175610.0, 'eval_mean_token_accuracy': 0.9002947194894155, 'epoch': 0.6627198020676858}
{'loss': 0.6926, 'grad_norm': 10.164896011352539, 'learning_rate': 0.001288977777777778, 'epoch': 0.7069011222055315}
{'eval_loss': 0.5212895274162292, 'eval_runtime': 49.7413, 'eval_samples_per_second': 603.121, 'eval_steps_per_second': 75.39, 'eval_num_tokens': 4451348.0, 'eval_mean_token_accuracy': 0.8976857974052429, 'epoch': 0.7069011222055315}
{'loss': 0.7043, 'grad_norm': 5.869482517242432, 'learning_rate': 0.0012445333333333333, 'epoch': 0.7510824423433772}
{'eval_loss': 0.5071898698806763, 'eval_runtime': 49.6194, 'eval_samples_per_second': 604.602, 'eval_steps_per_second': 75.575, 'eval_num_tokens': 4730535.0, 'eval_mean_token_accuracy': 0.8985433727741241, 'epoch': 0.7510824423433772}
{'loss': 0.7392, 'grad_norm': 3.1972742080688477, 'learning_rate': 0.001200088888888889, 'epoch': 0.795263762481223}
{'eval_loss': 0.5037437677383423, 'eval_runtime': 49.7553, 'eval_samples_per_second': 602.951, 'eval_steps_per_second': 75.369, 'eval_num_tokens': 5009547.0, 'eval_mean_token_accuracy': 0.8977347581704458, 'epoch': 0.795263762481223}
{'loss': 0.7564, 'grad_norm': 4.234501838684082, 'learning_rate': 0.0011556444444444445, 'epoch': 0.8394450826190687}
{'eval_loss': 0.5248302221298218, 'eval_runtime': 49.8322, 'eval_samples_per_second': 602.02, 'eval_steps_per_second': 75.252, 'eval_num_tokens': 5289934.0, 'eval_mean_token_accuracy': 0.8951885786771774, 'epoch': 0.8394450826190687}
{'loss': 0.7199, 'grad_norm': 3.0304887294769287, 'learning_rate': 0.0011112, 'epoch': 0.8836264027569144}
{'eval_loss': 0.4953915476799011, 'eval_runtime': 49.4757, 'eval_samples_per_second': 606.358, 'eval_steps_per_second': 75.795, 'eval_num_tokens': 5567918.0, 'eval_mean_token_accuracy': 0.8988333084662755, 'epoch': 0.8836264027569144}
{'loss': 0.7025, 'grad_norm': 4.427710056304932, 'learning_rate': 0.0010667555555555555, 'epoch': 0.9278077228947601}
{'eval_loss': 0.5244553685188293, 'eval_runtime': 49.502, 'eval_samples_per_second': 606.037, 'eval_steps_per_second': 75.755, 'eval_num_tokens': 5845536.0, 'eval_mean_token_accuracy': 0.8951673065741856, 'epoch': 0.9278077228947601}
{'loss': 0.7287, 'grad_norm': 3.546064615249634, 'learning_rate': 0.0010223111111111111, 'epoch': 0.9719890430326058}
{'eval_loss': 0.5181018114089966, 'eval_runtime': 49.5729, 'eval_samples_per_second': 605.17, 'eval_steps_per_second': 75.646, 'eval_num_tokens': 6125362.0, 'eval_mean_token_accuracy': 0.8956003139019012, 'epoch': 0.9719890430326058}
{'loss': 0.7407, 'grad_norm': 3.4877333641052246, 'learning_rate': 0.0009778666666666667, 'epoch': 1.0161703631704515}
{'eval_loss': 0.5127285122871399, 'eval_runtime': 49.8672, 'eval_samples_per_second': 601.598, 'eval_steps_per_second': 75.2, 'eval_num_tokens': 6403244.0, 'eval_mean_token_accuracy': 0.8975539122581482, 'epoch': 1.0161703631704515}
{'loss': 0.662, 'grad_norm': 3.3167295455932617, 'learning_rate': 0.0009334222222222223, 'epoch': 1.0603516833082973}
{'eval_loss': 0.5004185438156128, 'eval_runtime': 50.2124, 'eval_samples_per_second': 597.462, 'eval_steps_per_second': 74.683, 'eval_num_tokens': 6682179.0, 'eval_mean_token_accuracy': 0.9013268152952194, 'epoch': 1.0603516833082973}
{'loss': 0.6178, 'grad_norm': 6.691913604736328, 'learning_rate': 0.0008889777777777777, 'epoch': 1.104533003446143}
{'eval_loss': 0.48422303795814514, 'eval_runtime': 50.0847, 'eval_samples_per_second': 598.986, 'eval_steps_per_second': 74.873, 'eval_num_tokens': 6960122.0, 'eval_mean_token_accuracy': 0.9028226345698038, 'epoch': 1.104533003446143}
{'loss': 0.6353, 'grad_norm': 11.864312171936035, 'learning_rate': 0.0008445333333333333, 'epoch': 1.1487143235839887}
{'eval_loss': 0.4838902950286865, 'eval_runtime': 49.7343, 'eval_samples_per_second': 603.206, 'eval_steps_per_second': 75.401, 'eval_num_tokens': 7240881.0, 'eval_mean_token_accuracy': 0.903039363972346, 'epoch': 1.1487143235839887}
{'loss': 0.6496, 'grad_norm': 7.213500022888184, 'learning_rate': 0.0008000888888888888, 'epoch': 1.1928956437218343}
{'eval_loss': 0.47491589188575745, 'eval_runtime': 49.586, 'eval_samples_per_second': 605.01, 'eval_steps_per_second': 75.626, 'eval_num_tokens': 7520191.0, 'eval_mean_token_accuracy': 0.9051737188021342, 'epoch': 1.1928956437218343}
{'loss': 0.612, 'grad_norm': 27.984703063964844, 'learning_rate': 0.0007556444444444444, 'epoch': 1.2370769638596801}
{'eval_loss': 0.44413962960243225, 'eval_runtime': 49.7373, 'eval_samples_per_second': 603.169, 'eval_steps_per_second': 75.396, 'eval_num_tokens': 7796781.0, 'eval_mean_token_accuracy': 0.9101013742287953, 'epoch': 1.2370769638596801}
{'loss': 0.5612, 'grad_norm': 9.37232494354248, 'learning_rate': 0.0007112, 'epoch': 1.2812582839975257}
{'eval_loss': 0.4224175214767456, 'eval_runtime': 49.7326, 'eval_samples_per_second': 603.226, 'eval_steps_per_second': 75.403, 'eval_num_tokens': 8073752.0, 'eval_mean_token_accuracy': 0.9143533662954966, 'epoch': 1.2812582839975257}
{'loss': 0.6048, 'grad_norm': 2.440777063369751, 'learning_rate': 0.0006667555555555555, 'epoch': 1.3254396041353715}
{'eval_loss': 0.43342897295951843, 'eval_runtime': 49.676, 'eval_samples_per_second': 603.913, 'eval_steps_per_second': 75.489, 'eval_num_tokens': 8349946.0, 'eval_mean_token_accuracy': 0.9117500828584035, 'epoch': 1.3254396041353715}
{'loss': 0.5612, 'grad_norm': 4.424877643585205, 'learning_rate': 0.0006223111111111112, 'epoch': 1.3696209242732174}
{'eval_loss': 0.4078918695449829, 'eval_runtime': 49.7939, 'eval_samples_per_second': 602.483, 'eval_steps_per_second': 75.31, 'eval_num_tokens': 8629609.0, 'eval_mean_token_accuracy': 0.9158242046833038, 'epoch': 1.3696209242732174}
{'loss': 0.5605, 'grad_norm': 12.870882034301758, 'learning_rate': 0.0005778666666666667, 'epoch': 1.413802244411063}
{'eval_loss': 0.4162936508655548, 'eval_runtime': 49.8034, 'eval_samples_per_second': 602.368, 'eval_steps_per_second': 75.296, 'eval_num_tokens': 8910373.0, 'eval_mean_token_accuracy': 0.9161043980280559, 'epoch': 1.413802244411063}
{'loss': 0.5446, 'grad_norm': 19.315185546875, 'learning_rate': 0.0005334222222222223, 'epoch': 1.4579835645489088}
{'eval_loss': 0.4037223160266876, 'eval_runtime': 49.8927, 'eval_samples_per_second': 601.291, 'eval_steps_per_second': 75.161, 'eval_num_tokens': 9186716.0, 'eval_mean_token_accuracy': 0.918209886709849, 'epoch': 1.4579835645489088}
{'loss': 0.5324, 'grad_norm': 2.3829023838043213, 'learning_rate': 0.0004889777777777778, 'epoch': 1.5021648846867546}
{'eval_loss': 0.38484784960746765, 'eval_runtime': 49.7851, 'eval_samples_per_second': 602.59, 'eval_steps_per_second': 75.324, 'eval_num_tokens': 9464308.0, 'eval_mean_token_accuracy': 0.9205987705389659, 'epoch': 1.5021648846867546}
{'loss': 0.5167, 'grad_norm': 57.76995086669922, 'learning_rate': 0.00044453333333333337, 'epoch': 1.5463462048246002}
{'eval_loss': 0.3829002380371094, 'eval_runtime': 49.6888, 'eval_samples_per_second': 603.758, 'eval_steps_per_second': 75.47, 'eval_num_tokens': 9741614.0, 'eval_mean_token_accuracy': 0.9213454251448313, 'epoch': 1.5463462048246002}
{'loss': 0.4955, 'grad_norm': 6.587235927581787, 'learning_rate': 0.00040008888888888887, 'epoch': 1.5905275249624458}
{'eval_loss': 0.36857494711875916, 'eval_runtime': 49.6543, 'eval_samples_per_second': 604.177, 'eval_steps_per_second': 75.522, 'eval_num_tokens': 10018375.0, 'eval_mean_token_accuracy': 0.9236109891255697, 'epoch': 1.5905275249624458}
{'loss': 0.4749, 'grad_norm': 2.638620615005493, 'learning_rate': 0.0003556444444444444, 'epoch': 1.6347088451002916}
{'eval_loss': 0.35142165422439575, 'eval_runtime': 49.6461, 'eval_samples_per_second': 604.278, 'eval_steps_per_second': 75.535, 'eval_num_tokens': 10295429.0, 'eval_mean_token_accuracy': 0.9272250012715657, 'epoch': 1.6347088451002916}
{'loss': 0.4504, 'grad_norm': 29.708045959472656, 'learning_rate': 0.0003112, 'epoch': 1.6788901652381374}
{'eval_loss': 0.34965386986732483, 'eval_runtime': 49.7329, 'eval_samples_per_second': 603.222, 'eval_steps_per_second': 75.403, 'eval_num_tokens': 10573799.0, 'eval_mean_token_accuracy': 0.9273724341710409, 'epoch': 1.6788901652381374}
{'loss': 0.4456, 'grad_norm': 7.2558746337890625, 'learning_rate': 0.0002667555555555556, 'epoch': 1.723071485375983}
{'eval_loss': 0.32733669877052307, 'eval_runtime': 49.8298, 'eval_samples_per_second': 602.05, 'eval_steps_per_second': 75.256, 'eval_num_tokens': 10853742.0, 'eval_mean_token_accuracy': 0.9312961231072744, 'epoch': 1.723071485375983}
{'loss': 0.4359, 'grad_norm': 39.652286529541016, 'learning_rate': 0.0002223111111111111, 'epoch': 1.7672528055138288}
{'eval_loss': 0.3167840540409088, 'eval_runtime': 49.8546, 'eval_samples_per_second': 601.749, 'eval_steps_per_second': 75.219, 'eval_num_tokens': 11134917.0, 'eval_mean_token_accuracy': 0.9337285203138987, 'epoch': 1.7672528055138288}
{'loss': 0.3718, 'grad_norm': 4.008233070373535, 'learning_rate': 0.0001778666666666667, 'epoch': 1.8114341256516746}
{'eval_loss': 0.3077148497104645, 'eval_runtime': 49.8678, 'eval_samples_per_second': 601.59, 'eval_steps_per_second': 75.199, 'eval_num_tokens': 11411293.0, 'eval_mean_token_accuracy': 0.9350478054682414, 'epoch': 1.8114341256516746}
{'loss': 0.3706, 'grad_norm': 7.660393238067627, 'learning_rate': 0.00013342222222222222, 'epoch': 1.8556154457895202}
{'eval_loss': 0.30341047048568726, 'eval_runtime': 49.8123, 'eval_samples_per_second': 602.261, 'eval_steps_per_second': 75.283, 'eval_num_tokens': 11690651.0, 'eval_mean_token_accuracy': 0.9357016976515452, 'epoch': 1.8556154457895202}
{'loss': 0.3887, 'grad_norm': 9.797541618347168, 'learning_rate': 8.897777777777778e-05, 'epoch': 1.8997967659273658}
{'eval_loss': 0.29591137170791626, 'eval_runtime': 49.8418, 'eval_samples_per_second': 601.905, 'eval_steps_per_second': 75.238, 'eval_num_tokens': 11969687.0, 'eval_mean_token_accuracy': 0.9379772053400676, 'epoch': 1.8997967659273658}
{'loss': 0.3836, 'grad_norm': 2.5245630741119385, 'learning_rate': 4.4533333333333336e-05, 'epoch': 1.9439780860652116}
{'eval_loss': 0.2908961772918701, 'eval_runtime': 49.8273, 'eval_samples_per_second': 602.079, 'eval_steps_per_second': 75.26, 'eval_num_tokens': 12251571.0, 'eval_mean_token_accuracy': 0.9386721800645192, 'epoch': 1.9439780860652116}
{'loss': 0.3762, 'grad_norm': 24.6623477935791, 'learning_rate': 8.88888888888889e-08, 'epoch': 1.9881594062030574}
{'eval_loss': 0.2866804301738739, 'eval_runtime': 49.8, 'eval_samples_per_second': 602.41, 'eval_steps_per_second': 75.301, 'eval_num_tokens': 12529460.0, 'eval_mean_token_accuracy': 0.9392572840372722, 'epoch': 1.9881594062030574}
There were missing keys in the checkpoint model loaded: ['lm_head.weight'].
{'train_runtime': 3471.2591, 'train_samples_per_second': 51.854, 'train_steps_per_second': 6.482, 'train_loss': 0.6557698059082031, 'num_tokens': 12529460.0, 'mean_token_accuracy': 0.8729776560081376, 'epoch': 1.9881594062030574}
Time taken by training: 57.86 minutes
model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]model.safetensors:   0%|          | 229k/498M [00:00<03:39, 2.26MB/s]model.safetensors:   3%|▎         | 16.0M/498M [00:00<00:12, 37.9MB/s]model.safetensors:   6%|▋         | 32.0M/498M [00:00<00:10, 46.0MB/s]model.safetensors:  10%|▉         | 48.0M/498M [00:01<00:09, 47.5MB/s]model.safetensors:  13%|█▎        | 64.0M/498M [00:01<00:09, 44.1MB/s]model.safetensors:  16%|█▌        | 80.0M/498M [00:01<00:08, 48.7MB/s]model.safetensors:  19%|█▉        | 96.0M/498M [00:01<00:07, 52.7MB/s]model.safetensors:  23%|██▎       | 112M/498M [00:02<00:09, 38.7MB/s] model.safetensors:  26%|██▌       | 128M/498M [00:02<00:08, 43.9MB/s]model.safetensors:  29%|██▉       | 144M/498M [00:03<00:07, 48.9MB/s]model.safetensors:  32%|███▏      | 160M/498M [00:03<00:06, 49.1MB/s]model.safetensors:  35%|███▌      | 176M/498M [00:03<00:06, 50.3MB/s]model.safetensors:  39%|███▊      | 192M/498M [00:04<00:06, 44.4MB/s]model.safetensors:  42%|████▏     | 208M/498M [00:04<00:07, 41.3MB/s]model.safetensors:  45%|████▌     | 224M/498M [00:04<00:05, 46.0MB/s]model.safetensors:  48%|████▊     | 240M/498M [00:05<00:06, 41.2MB/s]model.safetensors:  51%|█████▏    | 256M/498M [00:05<00:05, 44.1MB/s]model.safetensors:  55%|█████▍    | 272M/498M [00:06<00:04, 46.7MB/s]model.safetensors:  58%|█████▊    | 288M/498M [00:08<00:11, 18.8MB/s]model.safetensors:  61%|██████    | 302M/498M [00:08<00:08, 24.5MB/s]model.safetensors:  62%|██████▏   | 308M/498M [00:08<00:08, 21.6MB/s]model.safetensors:  64%|██████▍   | 320M/498M [00:08<00:07, 25.3MB/s]model.safetensors:  68%|██████▊   | 336M/498M [00:09<00:04, 32.4MB/s]model.safetensors:  71%|███████   | 352M/498M [00:09<00:03, 38.0MB/s]model.safetensors:  74%|███████▍  | 368M/498M [00:09<00:03, 42.4MB/s]model.safetensors:  77%|███████▋  | 384M/498M [00:09<00:02, 46.6MB/s]model.safetensors:  80%|████████  | 400M/498M [00:10<00:02, 41.5MB/s]model.safetensors:  84%|████████▎ | 416M/498M [00:10<00:01, 46.0MB/s]model.safetensors:  87%|████████▋ | 432M/498M [00:11<00:01, 48.6MB/s]model.safetensors:  90%|█████████ | 448M/498M [00:11<00:01, 46.6MB/s]model.safetensors:  93%|█████████▎| 464M/498M [00:11<00:00, 49.8MB/s]model.safetensors:  96%|█████████▋| 480M/498M [00:13<00:00, 22.4MB/s]model.safetensors:  99%|█████████▉| 494M/498M [00:13<00:00, 29.3MB/s]model.safetensors: 100%|██████████| 498M/498M [00:13<00:00, 36.0MB/s]
